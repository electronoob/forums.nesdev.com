<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-gb">
<link rel="self" type="application/atom+xml" href="http://forums.nesdev.com/feed.php?f=9&amp;t=2129" />

<title>nesdev.com</title>
<subtitle>NES Development and Strangulation Records message boards</subtitle>
<link href="http://forums.nesdev.com/index.php" />
<updated>2006-09-28T05:09:59-07:00</updated>

<author><name><![CDATA[nesdev.com]]></name></author>
<id>http://forums.nesdev.com/feed.php?f=9&amp;t=2129</id>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2006-09-28T05:09:59-07:00</updated>
<published>2006-09-28T05:09:59-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18048#p18048</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18048#p18048"/>
<title type="html"><![CDATA[NTSC PPU composite video signal]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18048#p18048"><![CDATA[
I'm not sure if you're taking this into account, but contrary to blargg's image, Japanese NTSC ("NTSC-J") does not use a black setup of 7.5 IRE, but 0 IRE. Without compensation for the black setup, you'll get the NTSC-J "look". To get the "American" look, use signal = (signal - 0.075) / (1 - 0.075).<br /><br />Also the color burst amplitude might be of interest, as some TV compare it to what they think it should be like and amplify the signal accordingly.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Thu Sep 28, 2006 5:09 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[kevtris]]></name></author>
<updated>2006-09-26T22:48:20-07:00</updated>
<published>2006-09-26T22:48:20-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18026#p18026</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18026#p18026"/>
<title type="html"><![CDATA[Re: NTSC PPU composite video signal]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18026#p18026"><![CDATA[
<div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />Now that Kevtris has measured the <a href="http://nesdev.com/bbs/viewtopic.php?t=2113" class="postlink">PPU video signal</a> at the composite output jack, we can interpret it in terms of the NTSC standard:<br /><br /><img src="it's now http://h1.ripway.com/blargg/temp/ntsc_levels.png" alt="Image" /><br /><br />Taking the internal values Kevtris measured and adjusting for the range he measured at the composite output, I get 259 mV for black and 981 mV for white (relative to the sync level). Apparently the NES uses black for the blanking level. My question is, what does the decoder use as a zero reference? Bottom of sync or overall amplitude of waveform? Once I can figure out where to overlay this 981 mV range on the diagram above, I can determine where black falls.<br /></div><br /><br />I believe black level is used to get the '0 reference' for the decoder on a TV...  as for the maximum amplitude, I'm not quite sure.  One thing that interests me is the NES outputs 1 or 2 pixels of grey right before the rendered video.  I am guessing this pulse is there so that a completely or mostly black screen won't cause the TV to excessively brighten up the picture.  This is only a theory though.  Once I get my second revision of the FPGA hardware done, I will test this hypothesis out.  I am going to emulate the NES' exact NTSC output as my next goal.<br /><br />Once I get a PAL unit, I will do a similar job with its video hardware and then we'll have a fairly complete picture of what's going on.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=230">kevtris</a> — Tue Sep 26, 2006 10:48 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2006-09-26T04:59:30-07:00</updated>
<published>2006-09-26T04:59:30-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18004#p18004</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18004#p18004"/>
<title type="html"><![CDATA[NTSC PPU composite video signal]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=2129&amp;p=18004#p18004"><![CDATA[
Now that Kevtris has measured the <a href="http://nesdev.com/bbs/viewtopic.php?t=2113" class="postlink">PPU video signal</a> at the composite output jack, we can interpret it in terms of the NTSC standard:<br /><br /><img src="it's now http://h1.ripway.com/blargg/temp/ntsc_levels.png" alt="Image" /><br /><br />Taking the internal values Kevtris measured and adjusting for the range he measured at the composite output, I get 259 mV for black and 981 mV for white (relative to the sync level). Apparently the NES uses black for the blanking level. My question is, what does the decoder use as a zero reference? Bottom of sync or overall amplitude of waveform? Once I can figure out where to overlay this 981 mV range on the diagram above, I can determine where black falls.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Tue Sep 26, 2006 4:59 am</p><hr />
]]></content>
</entry>
</feed>