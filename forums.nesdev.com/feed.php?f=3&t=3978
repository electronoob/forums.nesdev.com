<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-gb">
<link rel="self" type="application/atom+xml" href="http://forums.nesdev.com/feed.php?f=3&amp;t=3978" />

<title>nesdev.com</title>
<subtitle>NES Development and Strangulation Records message boards</subtitle>
<link href="http://forums.nesdev.com/index.php" />
<updated>2008-03-20T13:58:14-07:00</updated>

<author><name><![CDATA[nesdev.com]]></name></author>
<id>http://forums.nesdev.com/feed.php?f=3&amp;t=3978</id>
<entry>
<author><name><![CDATA[ReaperSMS]]></name></author>
<updated>2008-03-20T13:58:14-07:00</updated>
<published>2008-03-20T13:58:14-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31877#p31877</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31877#p31877"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31877#p31877"><![CDATA[
Tell me about it. I've hacked GCC to try and improve the situation, but even that was mostly just adding a new type for them.<br /><br />The language semantics start to get really nasty when you start trying to pass or return structs by value, when those structs want to be in registers other than the integer GP regs, and that seems to be true on just about any platform, and when the semantics don't screw you over, the compiler and/or ABI will.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=8">ReaperSMS</a> — Thu Mar 20, 2008 1:58 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2008-03-20T12:07:40-07:00</updated>
<published>2008-03-20T12:07:40-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31876#p31876</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31876#p31876"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31876#p31876"><![CDATA[
<div class="quotetitle">ReaperSMS wrote:</div><div class="quotecontent"><br />As a side note, production compilers these days can barely get dead store elimination and math intrinsics right.<br /></div><br />Oh man, don't get me started on intrinsics.  The register allocation for SSE intrinsics in Microsoft's compiler is super stingy.  It also can't pass vector wrapper types by value on x86.  Trying to use SSE vector intrinsics from C++ is an exercise in frustration.   <img src="http://forums.nesdev.com/images/smilies/icon_confused.gif" alt=":?" title="Confused" /><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Thu Mar 20, 2008 12:07 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[ReaperSMS]]></name></author>
<updated>2008-03-19T19:34:30-07:00</updated>
<published>2008-03-19T19:34:30-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31852#p31852</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31852#p31852"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31852#p31852"><![CDATA[
Duplicating the OOE logic doesn't cost any more than duplicating an equal sized chunk of cache that ends up being useless because the execution units just puked out the entire pipeline because the compiler couldn't reshuffle instructions well enough. The set of scheduling rules one has to work around for certain chips (*cough* 360 *cough*) are many, complicated, and further screwed up by the 40-60 stage pipeline you get to try and schedule for.<br /><br />In theory, a JIT could have the same sort of advantage, but it will have to burn cycles doing all of the logic the OOE CPU would be doing, and would chew through tons of memory and cache duplicating any code for the various possibilities. That's after you solve the issue of determining exactly which version of the function to call at any particular point in the program, which can itself vary depending on the data or general state.<br /><br />The entire push *for* OOE execution is driven by the fact that static compile time instruction scheduling is a Very Difficult Nut To Crack, and most 'solutions' at some point involve a code explosion that will destroy any gains you may have achieved. I'd love to have a compiler that could perfectly schedule any code I could conceive of. I don't believe I will see such a beast in my lifetime.<br /><br />As a side note, production compilers these days can barely get dead store elimination and math intrinsics right.<br /><br />tepples: The handhelds are still using codewarrior as the official compiler, the general feeling is that the homebrew people have better tools. Most of the people working on the GC used SN's gcc port, which had it's issues, but it worked, and had a really nice debugger.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=8">ReaperSMS</a> — Wed Mar 19, 2008 7:34 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2008-03-19T16:34:24-07:00</updated>
<published>2008-03-19T16:34:24-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31848#p31848</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31848#p31848"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31848#p31848"><![CDATA[
<div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br /><div class="quotetitle">tepples wrote:</div><div class="quotecontent"><div class="quotetitle">blargg wrote:</div><div class="quotecontent">So you prefer to put instruction scheduling hardware in every computer rather than have it in the relatively fewer compilers used to build software?<br /></div><br />"Relatively fewer compilers"? Tell that to anybody who programs in a language that compiles to bytecode other than that of the hardware. There's a JIT for Java and .NET on a lot of PCs out there.</div><br />But it's not in hardware. Do you really not grasp what I was asserting? The cost of putting this software-based scheduler on every PC is virtually 0, while the cost of putting a hardware-based one is very much non-zero. It's just the cost of developing the compiler that matters, not duplicating it, unlike hardware.</div><br />It's apples and oranges though, because no compiler will ever be able to <br />avoid certain performance penalties of an in-order chip, which the out-of-order designs can mitigate or entirely absorb for you.<br /><br />And even if they could, its a bit unfair to claim that "the cost would be zero" because optimizing compilers are huge projects whose cost is measured in man-decades!   <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" /><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Wed Mar 19, 2008 4:34 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2008-03-19T16:29:15-07:00</updated>
<published>2008-03-19T16:29:15-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31846#p31846</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31846#p31846"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31846#p31846"><![CDATA[
<div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />So you prefer to put instruction scheduling hardware in every computer rather than have it in the relatively fewer compilers used to build software? It is true that the processor has more information about the values of variables for each execution of the code, but profile-guided compiler optimization can give the compiler the same information.<br /></div><br /><br />(1)  I agree with everything ReaperSMS said in his post above yours.<br /><br />(2)  Yes, I would prefer to have out-of-order execution hardware in every computer.  Its more effective than any static compiler can be, and it works on any program (not just ones compiled with some compiler or some optimization settings or whatever).  For general-purpose computers, it is usually worth it.  Of course when transistors or power efficiency is at a premium (cellphones and Xbox360's), this hardware might be too costly.<br /><br />Obviously, compiler scheduling has different goals for out-of-order chips than it has for an in-order chip.  For an out-of-order chip, it mainly wants to keep the functional units fed with lots of work, but it has a lot of flexibility and can try to minimize register pressure or optimize instruction issue (like the 4-1-1 decoding template mentioned above) or things like that.  For an in-order chip, it has to try and put things in a good order to try and minimize bubbles/hazards and pipeline stalls.  Of course lots of stalls will be for unpredictable things like cache misses, which the compiler can not do very much about.  Automatic prefetching by compilers has not been very successful in the real world, and all the compilers I know of don't do it at all (leaving it up to the programmer to do it where its needed).<br /><br />(3)  Profile-guided optimization is no silver bullet.  We usually don't even use it for console games, because of several factors: implementations that crash or produce incorrectly-optimized code, the difficulty of feeding it a repeatable but representative workload for training, and the fact that our code is being changed (bug fixes, etc) right up until the time we ship.  So there isn't really time to collect and combine a bunch of profile info to make PGO final builds with (and then we'd have to test them, and what if it exposed a PGO-only optimizer bug?)  With 50 programmers working on the same codebase, there's almost no point in trying to have a PGO build during production, either, because by the time the testers have run the regular binary enough to collect the PGO data to build the PGO version with, a new binary will be released to them with dozens or hundreds of source files changed, and the collected PGO data would then be useless!<br /><br />The risk of optimizer bugs is real, too.  Last week we found a non-PGO-related bug in the optimizer for MSVC, and that's like the most-tested compiler backend on Earth!  Without PGO, we can get repeatable builds--if the source code hasn't changed, probably the generated code won't change either.  With PGO, if you change the source code enough (and we always do) then your PGO data is not valid anymore and you have to collect new data.  The new data will cause different codegen decisions to be made, even when compiling the parts of the source code that *didn't* change.  It's a lot less repeatable, which makes it a lot less trustworthy, because the way we get confidence in it is by lots of hours of testing of the compiled binaries.<br /><br />Anyway, I don't think PGO can really improve low-level scheduling enough to make it competitive with OOE hardware.  Really what PGO is good for is higher-level decision making.  Things like, choosing which if/else case to put in straight-line code (the 80% one) and which one to move somewhere else (the 20% one).  Or, grouping infrequently-used code in one place in the program and all the frequently-used code in another place.  Or, choosing to aggressively unroll this frequently-executed loop (even inlining the somewhat large function called inside of it), versus choosing not to unroll or inline in this other less-frequently-used loop.  There are lots of other things compilers can do using info collected by PGO, which are sort of complementary to the low-level instruction scheduling stuff.  Ideally we'd have OOE hardware and use PGO builds on it when possible (the situation for x86 today).<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Wed Mar 19, 2008 4:29 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2008-03-19T15:02:12-07:00</updated>
<published>2008-03-19T15:02:12-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31838#p31838</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31838#p31838"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31838#p31838"><![CDATA[
<div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent">So you prefer to put instruction scheduling hardware in every computer rather than have it in the relatively fewer compilers used to build software?<br /></div><br />"Relatively fewer compilers"? Tell that to anybody who programs in a language that compiles to bytecode other than that of the hardware. There's a JIT for Java and .NET on a lot of PCs out there.</div><br />But it's not in hardware. Do you really not grasp what I was asserting? The cost of putting this software-based scheduler on every PC is virtually 0, while the cost of putting a hardware-based one is very much non-zero. It's just the cost of developing the compiler that matters, not duplicating it, unlike hardware.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Wed Mar 19, 2008 3:02 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2008-03-19T14:38:32-07:00</updated>
<published>2008-03-19T14:38:32-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31836#p31836</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31836#p31836"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31836#p31836"><![CDATA[
<div class="quotetitle">ReaperSMS wrote:</div><div class="quotecontent"><br />The wii situation is not a whole lot better, but that's mostly due to being stuck with codewarrior, crappiest compiler on earth.<br /></div><br />Why didn't Nintendo go to GCC for the Wii like it did for the handhelds?<br /><br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />So you prefer to put instruction scheduling hardware in every computer rather than have it in the relatively fewer compilers used to build software?<br /></div><br />"Relatively fewer compilers"? Tell that to anybody who programs in a language that compiles to bytecode other than that of the hardware. There's a JIT for Java and .NET on a lot of PCs out there.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Wed Mar 19, 2008 2:38 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2008-03-19T14:32:31-07:00</updated>
<published>2008-03-19T14:32:31-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31834#p31834</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31834#p31834"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31834#p31834"><![CDATA[
So you prefer to put instruction scheduling hardware in every computer rather than have it in the relatively fewer compilers used to build software? It is true that the processor has more information about the values of variables for each execution of the code, but profile-guided compiler optimization can give the compiler the same information.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Wed Mar 19, 2008 2:32 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[ReaperSMS]]></name></author>
<updated>2008-03-19T14:07:55-07:00</updated>
<published>2008-03-19T14:07:55-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31829#p31829</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31829#p31829"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31829#p31829"><![CDATA[
This is getting rather off topic =P<br /><br />I think we can agree that modern x86's are RISC cores with an excessively complicated, but generally compact code in front. Sort of like a Mirror Universe Thumb set.<br /><br />The two threads per core on the 360 do help, but they can easily clog each other up.<br /><br />It really comes down to the difference between what the compiler knows at compile time, and what the chip knows at runtime. Restrict can help, but it can't solve every aliasing uncertainty at compile time. At runtime, there are no uncertainties past speculative execution across predicted branches -- the chip knows what memory you're accessing, and knows exactly what registers you're working with. <br /><br />On the high end processors (not arm) the compiler can't even addres all of the avaliable registers, due to renaming. X86's haven't been saddled with the base 8 registers since the P6. <br /><br />In-Order chips tend to be tied to exactly the architecturally exposed set, and punting on working around data hazards to the compiler breaks down in that situation unless you have enuogh registers to avoid reusing one for different purposes within the pipeline depth. When you have a 50 stage pipeline, and every instruction is 3 or 4 address, that ranges between difficult and impossible.<br /><br />I'm a big fan of OOE chips, as they make the compiler's job much easier. Optimal compile time scheduling is one of those nasty little problems that's been an active research topic for the last 15 years. They haven't found a really good solution yet, and the last chip that tried to rely on the compiler being smart was the Itanic. The ps3 and 360 will probably be struggling with compiler quality until they get EOL'd. The wii situation is not a whole lot better, but that's mostly due to being stuck with codewarrior, crappiest compiler on earth.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=8">ReaperSMS</a> — Wed Mar 19, 2008 2:07 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2008-03-19T13:11:24-07:00</updated>
<published>2008-03-19T13:11:24-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31827#p31827</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31827#p31827"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31827#p31827"><![CDATA[
<div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br /><div class="quotetitle">ReaperSMS wrote:</div><div class="quotecontent">Technically the compiler can look at a lot more, but language semantics usually restrict what it can do<br /></div><br />C99 is supposed to help solve this by adding a new keyword <strong>restrict</strong> that specifies the semantics of a function with respect to aliasing.</div><br />Yes, restrict helps on RISC machines a lot, where it's the compiler that must move memory loads as early as possible, due to the delay until the result is available. But on x86, restrict helps much less because the instruction set favors non-parallel code.<br /><br /><div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent">The only hard information is how fast a particular pair of algorithms execute on a particular processor<br /></div><br />What do you want to see? A space-time-accuracy comparison of CORDIC and LUT approaches to cosine calculation on a Nintendo DS, perhaps?</div><br />No; my point was that one should code the algorithm both ways in the actual program and measure the difference in speed, rather than rely on general benchmarks.<br /><br /><div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent">If you write to the array then access it again, some compilers won't be smart enough to determine that the a and b pointers didn't change, so it will re-read them before the next access; in some cases, the compiler can't prove that they won't change, so it must re-read them.<br /></div><br />I thought that's what the <strong>volatile</strong> keyword was for: to specify that memory won't change except across a function call, unless the keyword is present. There's also the tradeoff of rereading the address from the data section vs. rereading it from the code.</div><br />No, this is about a memory write that the compiler inserted, and it not being able to prove that it didn't modify some other value also in memory. As you said above, restrict is the answer to this aliasing issue. volatile would force this unoptimal situation by making the compiler reload the pointer every time it's used.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Wed Mar 19, 2008 1:11 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Dwedit]]></name></author>
<updated>2008-03-19T08:16:42-07:00</updated>
<published>2008-03-19T08:16:42-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31814#p31814</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31814#p31814"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31814#p31814"><![CDATA[
Compilers definitely generate crap code for global variables.  You can get smaller/faster code by having local variable copies of them.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=53">Dwedit</a> — Wed Mar 19, 2008 8:16 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2008-03-19T05:07:42-07:00</updated>
<published>2008-03-19T05:07:42-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31803#p31803</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31803#p31803"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31803#p31803"><![CDATA[
<div class="quotetitle">ReaperSMS wrote:</div><div class="quotecontent"><br />The chip can usually do a better job of scheduling than the compiler, as it has a lot more information regarding what addresses everything is dealing with, so aliasing is not much of an issue.<br /><br />Technically the compiler can look at a lot more, but language semantics usually restrict what it can do<br /></div><br />C99 is supposed to help solve this by adding a new keyword <strong>restrict</strong> that specifies the semantics of a function with respect to aliasing.<br /><br /><div class="quotetitle">ReaperSMS wrote:</div><div class="quotecontent"><br />and it can't really look outside of the current function most of the time.<br /></div><br />It can if the other function is in the same source code file and <strong>static</strong>. That's at least part of how it decides to consider something for inlining.<br /><br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />But what I meant by "modern CPU designs" was pretty much all x86-based chips made since the Pentium Pro in the mid-90's.<br /></div><br />You and blargg are both right. The P6 architecture as amended is comparatively modern (even if a decade old), but the underlying 8086 bytecode is ancient.<br /><br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />They use register renaming to a file of 40 or more internal registers, and break all of the quirky and complex x86 instructions up into simple, RISC micro-ops before executing them.<br /></div><br />On the other hand, the MIPS, PowerPC, and ARM bytecodes are designed to be decoded to micro-ops using less circuitry. That's pretty much the big difference between CISC and RISC, but at a slight cost in code density for RISC. The RISC people have made various compromises to improve code density, such as the Thumb bytecode.<br /><br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />As for OOE, current x86 chips can have like 96 micro-ops in flight and issue 3 or more instructions every cycle, so they are able to start lots of new instructions while waiting for already-running instructions to finish, even across things like call/return boundaries.<br /></div><br />I can see how handling out-of-order across basic blocks might be a win on a system with few interrupts. But is this true of typical applications?<br /><br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />It's hard to impossible for a compiler to match that level of performance on an in-order execution chip. But I'd say the three cores of the 360 more than makes up for the difference!<br /></div><br />That and especially the two threads per core.<br /><br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />The only hard information is how fast a particular pair of algorithms execute on a particular processor<br /></div><br />What do you want to see? A space-time-accuracy comparison of CORDIC and LUT approaches to cosine calculation on a Nintendo DS, perhaps?<br /><br /><div class="quotetitle">Nessie wrote:</div><div class="quotecontent"><br />I believe [accessing a buffer allocated statically] uses absolute addressing (something like 0x00010000+0x4000) whereas [accessing a buffer created with malloc()] would have to use a register as a pointer (esi+0x4000). So, the first option would probably be faster since it's easier to pipeline when no pointer register is involved.<br /></div><br />On ARM CPUs such as that of the DS, an immediate quantity must be an 8-bit number rotated left by 0, 2, 4, 6, ..., 28, or 30 bits. Any other constant must be stored after the return instruction and loaded relative to the program counter. RAM is at 0x02000000 through 0x023FFFFF, and the absolute address of a statically allocated variable might be 0x0201acc4, which doesn't fit the immediate rule.<br /><br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />If you write to the array then access it again, some compilers won't be smart enough to determine that the a and b pointers didn't change, so it will re-read them before the next access; in some cases, the compiler can't prove that they won't change, so it must re-read them.<br /></div><br />I thought that's what the <strong>volatile</strong> keyword was for: to specify that memory won't change except across a function call, unless the keyword is present. There's also the tradeoff of rereading the address from the data section vs. rereading it from the code.<br /><br />Split.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Wed Mar 19, 2008 5:07 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2008-03-18T18:44:05-07:00</updated>
<published>2008-03-18T18:44:05-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31793#p31793</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31793#p31793"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31793#p31793"><![CDATA[
Without context, it's hard to say. Here's a more interesting comparison:<br /><div class="codetitle"><b>Code:</b></div><div class="codecontent">struct X &#123;<br />    unsigned char a &#91;0x4000&#93;;<br />    unsigned char b &#91;0x4000&#93;;<br />&#125;;<br /><br />struct Y &#123;<br />    unsigned char* a;<br />    unsigned char* b;<br />&#125;;<br /><br />void func&#40; T* t &#41;<br />&#123;<br />    t-&gt;a &#91;0x1234&#93; = 0;<br />    t-&gt;a &#91;0x2345&#93; = 0;<br />&#125;</div><br />In this case, using X is probably more efficient since there are fewer memory accesses needed. All that is needed to access an element of a or b is a pointer to the X structure and an offset. Contrast that with Y where a pointer to the structure is needed, then the a or b pointer must be read from that, and finally the offset added. If you write to the array then access it again, some compilers won't be smart enough to determine that the a and b pointers didn't change, so it will re-read them before the next access; in some cases, the compiler can't prove that they won't change, so it must re-read them.<br /><br />In some cases, you can use Y and make local copies of the pointers to help the compiler prove that they don't need to be re-read, but this will use more registers so it's still not as good.<br /><div class="codetitle"><b>Code:</b></div><div class="codecontent">void func&#40; Y* y &#41;<br />&#123;<br />    unsigned char* ya = y-&gt;a;<br />    ya &#91;0x1234&#93; = 0;<br />    ya &#91;0x2345&#93; = 0;<br />&#125;</div><br />As far as globals, I've found that many compilers generate worse code for them. As always, the only authority on efficiency is measurement of the full program. Everything else is just a source of ideas to put to the test.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Tue Mar 18, 2008 6:44 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Nessie]]></name></author>
<updated>2008-03-18T17:50:40-07:00</updated>
<published>2008-03-18T17:50:40-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31792#p31792</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31792#p31792"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31792#p31792"><![CDATA[
<div class="quotetitle">Fx3 wrote:</div><div class="quotecontent"><br /><div class="quotetitle">Dwedit wrote:</div><div class="quotecontent">But it's awesome debate about the merits of lookup tables!<br /><br />On a GBA and NDS, lookup tables are king.<br /></div><br /><br />&lt;newbie&gt; Is this...<br /><br />unsigned char cache[0x4000];<br /><br />...equals to this...<br /><br />unsigned char *cache = malloc(0x4000); <br /><br />...when accessing it like cache[0x3f00]??<br /><br />&lt;/newbie&gt;</div><br /><br />I'm no expert so don't take my word for it, but I believe the first option uses absolute addressing (something like 0x00010000+0x4000) whereas the second would have to use a register as a pointer (esi+0x4000). So, the first option would probably be faster since it's easier to pipeline when no pointer register is involved.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=12">Nessie</a> — Tue Mar 18, 2008 5:50 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Zepper]]></name></author>
<updated>2008-03-18T17:11:52-07:00</updated>
<published>2008-03-18T17:11:52-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31791#p31791</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31791#p31791"/>
<title type="html"><![CDATA[To lookup or not to lookup?]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=3978&amp;p=31791#p31791"><![CDATA[
<div class="quotetitle">Dwedit wrote:</div><div class="quotecontent"><br />But it's awesome debate about the merits of lookup tables!<br /><br />On a GBA and NDS, lookup tables are king.<br /></div><br /><br />&lt;newbie&gt; Is this...<br /><br />unsigned char cache[0x4000];<br /><br />...equals to this...<br /><br />unsigned char *cache = malloc(0x4000); <br /><br />...when accessing it like cache[0x3f00]??<br /><br />&lt;/newbie&gt;<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=39">Zepper</a> — Tue Mar 18, 2008 5:11 pm</p><hr />
]]></content>
</entry>
</feed>