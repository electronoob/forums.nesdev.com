<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html dir="ltr" lang="en-gb">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta http-equiv="Content-Style-Type" content="text/css">
<meta http-equiv="Content-Language" content="en-gb">
<title>nesdev.com :: View topic - Is an archived version of the current nesdev forum worth it?</title>

<style type="text/css">
<!--

body {
	font-family: Verdana,serif;
	font-size: 10pt;
}

img {
	border: 0;
}

td {
	font-family: Verdana,serif;
	font-size: 10pt;
	line-height: 150%;
}

.code, .codecontent, 
.quote, .quotecontent {
	margin: 0 5px 0 5px;
	padding: 5px;
	font-size: smaller;
	border: black solid 1px;
}

.quotetitle {
	color: black;
	display : block;
	font-weight: bold;
}

.forum {
	font-family: Arial,Helvetica,sans-serif;
	font-weight: bold;
	font-size: 18pt;
}

.topic {
	font-family: Arial,Helvetica,sans-serif;
	font-size: 14pt;
	font-weight: bold;
}

.gensmall {
	font-size: 8pt;
}

hr {
	color: #888;
	height: 3px;
	border-style: solid;
}

hr.sep {
	color: #aaa;
	height: 1px;
	border-style: dashed;
}
//-->
</style>

</head>
<body>

<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
<tr>
	<td colspan="2" align="center"><span class="Forum">nesdev.com</span><br /><span class="gensmall"><a href="http://forums.nesdev.com/">http://forums.nesdev.com/</a></span></td>
</tr>
<tr>
	<td colspan="2"><br /></td>
</tr>
<tr>
	<td><span class="topic">Is an archived version of the current nesdev forum worth it?</span><br /><span class="gensmall"><a href="http://forums.nesdev.com/viewtopic.php?f=5&amp;t=8837">http://forums.nesdev.com/viewtopic.php?f=5&amp;t=8837</a></span></td>
	<td align="right" valign="bottom"><span class="gensmall">Page <strong>3</strong> of <strong>5</strong></span></td>
</tr>
</table>



	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>koitsu</b> [ Mon Apr 23, 2012 11:47 pm ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">Banshaku wrote:</div><div class="quotecontent">@Koitsu:<br /><br />wouldn't if Tepples had a local copy of the bbs db and have fun to his heart content be easier in a way? The database is not that big actually.</div>
<br />
<br />The issue then becomes formulating MySQL queries that get back exactly what Tepples wants.  This might require a lot of reverse-engineering the phpBB 2.x code, which like most open-source forum projects is spaghetti.
<br />
<br />If he's willing to do and write all that, I will be more than happy to put up a mysqldump of the DB (will provide URL in the Moderators forum).  If he's not sure and needs the DB + schema to work with for starters, that's fine too, I'll be happy to put up a DB dump.  Let me know either way if this is what we want to do, as I'm fine with it.
<br />
<br />Just remember that the DB dump immediately becomes outdated the instant someone posts on the forum, which is why we're trying to figure out what's best (re: locking down the forum so nobody can post, migrate to something new, or what).
<br />
<br />Folks reading this should probably also <a href="http://nesdev.com/bbs/viewtopic.php?p=92824#92824" class="postlink">read this</a>.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Tue Apr 24, 2012 5:27 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">Anthony J. Bentley wrote:</div><div class="quotecontent">Archives make searching for particular topics that much harder</div><br />I'll see what I can do about search, now that I can get the full text of every post.<br /><br /><div class="quotetitle">koitsu wrote:</div><div class="quotecontent">It's now installed.</div><br />Thank you. I might try harvesting phpBB 2 from the ndwiki shell account in a couple days, after I figure out how to harvest wwwThreads. I've pretty much finished harvesting the wiki already, and I just need to run small updates weekly to bring it up to date with recent changes.<br /><br /><div class="quotetitle">koitsu wrote:</div><div class="quotecontent">The issue then becomes formulating MySQL queries that get back exactly what Tepples wants.  This might require a lot of reverse-engineering the phpBB 2.x code, which like most open-source forum projects is spaghetti.</div><br />If I were to reverse engineer data out of a dump, I'd probably put MySQL and phpMyAdmin on my laptop and do it from the tables. That's what I did at my last job: it involved reverse engineering a commercial off-the-shelf order fulfillment package from the tables in order to allow other custom tools to interact with the data through ODBC.<br /><br /><div class="quotetitle">koitsu wrote:</div><div class="quotecontent">Just remember that the DB dump immediately becomes outdated the instant someone posts on the forum</div>
<br />Yeah, that's a big difference between phpBB 2 and MediaWiki. The MediaWiki API allows pulling the last modified date for each page, so I know exactly what to update.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>Banshaku</b> [ Tue Apr 24, 2012 7:36 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />I may understand that we could want an archive of the bbs but I still don't get why we crawl the wiki if we are going to use it as-is on the next server? Or did I miss something?
<br />
<br />So what is the purpose of the crawling of the wiki? Is it to remake the static html version that couldn't be done anymore? I would like to know the goal.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>Hamburgler</b> [ Tue Apr 24, 2012 7:52 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />Why not just grab a backup of the database from the phpBB admin control panel?

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Tue Apr 24, 2012 7:56 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">Banshaku wrote:</div><div class="quotecontent">So what is the purpose of the crawling of the wiki? Is it to remake the static html version that couldn't be done anymore?</div><br />That was in fact the original goal of my wiki crawler.<br /><br /><div class="quotetitle">Hamburgler wrote:</div><div class="quotecontent">Why not just grab a backup of the database from the phpBB admin control panel?</div>
<br />THANK YOU. I didn't know that was there. That'll simplify some things.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>Banshaku</b> [ Tue Apr 24, 2012 8:12 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />I see. If it does work well, it will be useful at a later stage since the previous wikimedia plug-in doesn't work anymore.  
<br />
<br />For now, I don't think you should worry too much about the wiki crawling. My guess is the focus should be done on what is the next stage for the bbs with Memblers, if an archive is a good thing or not. 
<br />
<br />Or maybe the focus should be move first then find a solution of the archive later.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Tue Apr 24, 2012 11:55 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />I tried running my wwwThreads crawler on the Parodius SSH server so that it'll run without any external traffic. I found there's <a href="http://docs.python.org/release/2.6.6/library/sqlite3.html" class="postlink">another Python module that's not installed</a>.
<br /><div class="codetitle"><b>Code:</b></div><div class="codecontent">Traceback &#40;most recent call last&#41;:<br />&nbsp; File &quot;./scrape_bb1.py&quot;, line 212, in &lt;module&gt;<br />&nbsp; &nbsp; main&#40;&#41;<br />&nbsp; File &quot;./scrape_bb1.py&quot;, line 198, in main<br />&nbsp; &nbsp; import sqlite3<br />&nbsp; File &quot;/usr/local/lib/python2.6/sqlite3/__init__.py&quot;, line 24, in &lt;module&gt;<br />&nbsp; &nbsp; from dbapi2 import *<br />&nbsp; File &quot;/usr/local/lib/python2.6/sqlite3/dbapi2.py&quot;, line 27, in &lt;module&gt;<br />&nbsp; &nbsp; from _sqlite3 import *<br />ImportError: No module named _sqlite3</div>

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>koitsu</b> [ Tue Apr 24, 2012 4:00 pm ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />I'm working on fixing the lack of sqlite3.  It appears the FreeBSD port for this is horribly, *horribly* broken.  I am not a happy camper.
<br />
<br />Edit: I see the problem.  It's still idiocy/brokenness in the FreeBSD ports system, but I know how to address it.
<br />
<br />Sorry about all the lack of modules -- absolutely no user of ours uses Python.  The only reason Python is installed at all is because it's a build requirement for Apache.  (I threw quite a tantrum on mailing lists about that too.)
<br />
<br />Edit: Done.  Please note I had to upgrade Python to 2.6.8 to get any of this to work.  That means html5lib had to be upgraded, etc..  So if you run into new problems in that library, we'll deal with that when we get there.  Of course, I'm also not sure why a web crawler would need SQLite.......

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Wed Apr 25, 2012 7:02 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">koitsu wrote:</div><div class="quotecontent">I'm working on fixing the lack of sqlite3<br />[...]<br />Edit: Done.</div><br />Thanks.<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent">Of course, I'm also not sure why a web crawler would need SQLite.......</div>
<br />It lets me store exactly how far along I am in the crawl, and it puts all the harvested pages in a single file so that they don't use up so many inodes and so much slack space. Then I can gzip up a single .sqlite file and pull it to my machine once I'm done. I'll try it this evening after I've made a refinement to the schema.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>clueless</b> [ Wed Apr 25, 2012 8:09 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">tepples wrote:</div><div class="quotecontent">It lets me store exactly how far along I am in the crawl, and it puts all the harvested pages in a single file so that they don't use up so many inodes and so much slack space. Then I can gzip up a single .sqlite file and pull it to my machine once I'm done. I'll try it this evening after I've made a refinement to the schema.</div>
<br />
<br />SQLite rocks.  I use it for several projects and have a fair bit of experience with it.  SQLite has a very vibrant user + dev community.
<br />
<br />A suggestion: before you compress the sqlite database, "VACUUM" it first.  Even on an "insert only" database, vacuum can typically make it smaller (it re-balances the b-trees).  On a database that has had updates and deletes, vacuum will almost always make the file smaller.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Wed Apr 25, 2012 10:37 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">clueless wrote:</div><div class="quotecontent">before you compress the sqlite database, "VACUUM" it first.</div>
<br />Thanks for the tip. I added a VACUUM statement at the end of the wwwThreads crawler.
<br />
<br />As of right now, the wiki is crawled, and wwwThreads is in progress. My next things to do: <ul><li>Make downloaded wiki data browsable </li><li>Make downloaded wwwThreads data browsable </li><li>Rewrite phpBB 2 crawler to store information more efficiently based on what I learned making the wwwThreads crawler </li><li>Make a JavaScript full-text search engine for all three crawled sites </li></ul>
<br />Once these scripts stabilize, I'll make them available in case someone else on Parodius wants to archive a site.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>Zepper</b> [ Wed Apr 25, 2012 2:44 pm ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />Thanks for making a backup of this forum. <img src="./images/smilies/icon_smile.gif" alt=":)" title="Smile" /> It would be nasty restarting from scratch. Basically, all the <em>golden info</em> is inside here.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Wed Apr 25, 2012 8:28 pm ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">Hamburgler wrote:</div><div class="quotecontent">Why not just grab a backup of the database from the phpBB admin control panel?</div>
<br />Here's why not:
<br />
<br /><strong>Fatal error</strong>: Allowed memory size of 134217728 bytes exhausted (tried to allocate 32 bytes) in <strong>/home/memblers/nesdev/bbs/db/mysql4.php</strong> on line <strong>199</strong>
<br />
<br />I tried to back up the database and I got that error around the time the dump reached phpbb_search_wordlist.
<br />
<br />Anyway, I've crawled wwwthreads and the wiki in their entirety.
<br /><ul><li>wwwthreads.sqlite is 7.8 MiB unzipped or 2.2 MiB gzipped. It was crawled from within Parodius. It contains the HTML of each post in each topic. </li><li>nesdevwiki.sqlite is 4.6 MiB unzipped or about 1 MiB gzipped. It was crawled from home, and I update it incrementally about once a week. It contains both the wiki markup and HTML versions of each post. It's so much smaller than a database dump because it contains only the latest revision, not the entire revision history of each article. </li></ul>
<br />So if I can't export a database dump, I'll have to build a database of publicly available HTML posts. I've run the crawler on my computer (limited to GB, SNES, and Other Retro forums) to give me a limited data set with which to test a reformatting tool, and I'll run it again within Parodius in mid-August to get a full snapshot.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>koitsu</b> [ Wed Apr 25, 2012 9:13 pm ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" /><div class="quotetitle">tepples wrote:</div><div class="quotecontent">Here's why not:<br /><br /><strong>Fatal error</strong>: Allowed memory size of 134217728 bytes exhausted (tried to allocate 32 bytes) in <strong>/home/memblers/nesdev/bbs/db/mysql4.php</strong> on line <strong>199</strong></div>
<br />This is due to a PHP setting called <a href="http://www.php.net/manual/en/ini.core.php#ini.memory-limit" class="postlink">memory_limit</a>, which defaults to 128MBytes (give or take some room).  We can adjust this.  However, it indicates that phpBB 2 is horribly inefficient at doing the backup (it should not be storing all of this crap in memory.  Grrr...)
<br />
<br />Tepples, I'll work on getting you a full mysqldump of the DB tonight and give you a URL for it via a PM.  You can download it to your hearts content + at high speed, as it'll be hosted at a place which has no bandwidth limits whatsoever.  I'll name the file with the UNIX timestamp of when the dump was taken, and the dump will use table locking so it should be intact.
<br />
<br />Edit: PM sent.

		

		</td>
	</tr>
	</table>


	<hr width="85%" />

	<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
	<tr>
		<td width="10%" nowrap="nowrap">Author:&nbsp;</td>
		<td><b>tepples</b> [ Thu Apr 26, 2012 10:23 am ]</td>
	</tr>
	<tr>
		<td width="10%" nowrap="nowrap">Post subject:&nbsp;</td>
		<td><b></b></td>
	</tr>
	<tr>
		<td colspan="2"><hr class="sep" />Snapshot saved. Thanks.
<br />
<br />In my full scrape of SNES, GB, and Other Retro forums, I've been able to transform links within posts to links to static HTML versions of the respective topics, as well as pages in both hostnames that the wiki has used (nesdevwiki.ath.cx and wiki.nesdev.com). Of course, I'll update the specific formats once migration plans become more solid.

		

		</td>
	</tr>
	</table>


<hr width="85%" />

<table width="85%" cellspacing="3" cellpadding="0" border="0" align="center">
<tr>
	<td><span class="gensmall">Page <strong>3</strong> of <strong>5</strong></span></td>
	<td align="right"><span class="gensmall">All times are UTC - 7 hours </span></td>
</tr>
<tr>
	<td colspan="2" align="center"><span class="gensmall">Powered by phpBB&reg; Forum Software &copy; phpBB Group<br />http://www.phpbb.com/</span></td>
</tr>
</table>

</body>
</html>