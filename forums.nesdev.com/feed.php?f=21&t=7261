<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-gb">
<link rel="self" type="application/atom+xml" href="http://forums.nesdev.com/feed.php?f=21&amp;t=7261" />

<title>nesdev.com</title>
<subtitle>NES Development and Strangulation Records message boards</subtitle>
<link href="http://forums.nesdev.com/index.php" />
<updated>2013-08-24T16:14:33-07:00</updated>

<author><name><![CDATA[nesdev.com]]></name></author>
<id>http://forums.nesdev.com/feed.php?f=21&amp;t=7261</id>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2013-08-24T16:14:33-07:00</updated>
<published>2013-08-24T16:14:33-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117018#p117018</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117018#p117018"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117018#p117018"><![CDATA[
I believe that slew rate is due to limited drive current of an amplifier, combined with the inevitable capacitance in parallel with the load. Here's a great picture of how a limited slew rate can cause a phase shift (red=in, green=out):<br /><br /><img src="http://i.imgur.com/JdzWRsc.gif" alt="Image" /><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Sat Aug 24, 2013 4:14 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2013-08-24T15:33:11-07:00</updated>
<published>2013-08-24T15:33:11-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117013#p117013</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117013#p117013"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117013#p117013"><![CDATA[
As I said, I'm no EE, but perhaps an amplifier tracks the input voltage better when it's feeding a smaller load. I only took time to learn about slew rate in the first place when I realized it led to the same distortion phenomenon as DPCM slope overload.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sat Aug 24, 2013 3:33 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2013-08-24T14:38:29-07:00</updated>
<published>2013-08-24T14:38:29-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117010#p117010</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117010#p117010"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117010#p117010"><![CDATA[
Empirically I had found that the value must be about 1.3, so that seems correct. Thanks.<br /><div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br />Two consoles looking different on one TV but the same on another might be an impedance mismatch.<br /></div>And slew rate would cause an impedance mismatch to affect phase?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Sat Aug 24, 2013 2:38 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2013-08-24T14:08:45-07:00</updated>
<published>2013-08-24T14:08:45-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117008#p117008</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117008#p117008"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117008#p117008"><![CDATA[
<div class="quotetitle">NewRisingSun wrote:</div><div class="quotecontent"><br /><div class="quotetitle">tepples wrote:</div><div class="quotecontent">True, an ideal brick wall at 4.2 MHz will cause the sine wave to have a bigger peak-to-peak amplitude.<br /></div><br />By how much? <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /></div><br />Google <tt style="margin-left: 2px; margin-right: 2px; padding:3px; background-color: #3355aa; color: white;">fourier transform of square wave</tt> finds <a href="https://en.wikipedia.org/wiki/Square_wave" class="postlink">&quot;Square wave&quot; on Wikipedia</a>, which shows the amplitude of the fundamental frequency as 4/π ≈ 1.27, or 20 log(4/π) ≈ 2.1 dB above the flat part of the ideal square wave.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sat Aug 24, 2013 2:08 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2013-08-24T13:49:46-07:00</updated>
<published>2013-08-24T13:49:46-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117007#p117007</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117007#p117007"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117007#p117007"><![CDATA[
<div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br />True, an ideal brick wall at 4.2 MHz will cause the sine wave to have a bigger peak-to-peak amplitude.<br /></div>By how much? <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /><div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br />But the real amplitude depends on how the filter's transfer function looks around 3.58 MHz (fundamental) and 10.74 MHz (third harmonic, which is the first overtone of a square wave). Attenuation of -6 dB per octave, for example, will turn a square wave into a triangle wave, and if the corner isn't well above 4 MHz, it'll reduce the amplitude of the fundamental.<br /></div>The way I read the drawing in the NTSC document from 1954, it's 0% attenuation at 4.2 MHz and 100% attenuation at 4.5 MHz. (The 1941 document on the other hand has a drawing indicating 0% attenuation at 4.0 MHz and 100% attenuation at 4.5 MHz.)<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Sat Aug 24, 2013 1:49 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2013-08-24T13:28:03-07:00</updated>
<published>2013-08-24T13:28:03-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117005#p117005</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117005#p117005"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117005#p117005"><![CDATA[
<div class="quotetitle">NewRisingSun wrote:</div><div class="quotecontent"><br />If the square-wave 3.58 MHz signal is filtered into a sine-wave, its peak-to-peak amplitude would be larger, but by how much?<br /></div><br />True, an ideal brick wall at 4.2 MHz will cause the sine wave to have a bigger peak-to-peak amplitude. But the real amplitude depends on how the filter's transfer function looks around 3.58 MHz (fundamental) and 10.74 MHz (third harmonic, which is the first overtone of a square wave). Attenuation of -6 dB per octave, for example, will turn a square wave into a triangle wave, and if the corner isn't well above 4 MHz, it'll reduce the amplitude of the fundamental.<br /><br />Disclaimer: I have more of a digital signal processing background than an analog EE background.<br /><br />Two consoles looking different on one TV but the same on another might be an impedance mismatch. The TV where they look the same might have a lower input load.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sat Aug 24, 2013 1:28 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2013-08-24T13:21:12-07:00</updated>
<published>2013-08-24T13:21:12-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117003#p117003</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117003#p117003"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117003#p117003"><![CDATA[
<div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br />If there's more phase delay on $18 and $28 than on $08 and $38, you've found your culprit.<br /></div>That's not what I've seen with the NES. And it doesn't explain why two consoles look different on one TV, but the same on another.<br /><br />I agree however that NTSC is definitely susceptible to the slew rate phenomenon: contrary to what is typically claimed, the famous NTSC phase shift problem is not caused by strange things happening to terrestial signals in the air, but by receiver equipment and especially transmitters having an amplitude-dependent phase shift. The first NTSC transmitters <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&amp;arnumber=4505220" class="postlink">shifted the highest amplitudes 30 degrees further than the lowest amplitudes</a>; adjusting the (amplitude-independent) hue control on the receiver could therefore only result in either bright or dim colors looking correct. Hence the popularity of PAL, whose patent specifically mentions its ability to perfectly correct this &quot;differential phase error&quot;, as it's called.<br /><br />Another question, which tepples might be able to answer: SMPTE-170M states that the peak-to-peak color burst amplitude shall be 40 IRE. The NES outputs about 50 IRE (with 75 ohm load), suggesting that saturation ought to be attenuated by 40/50. However, SMPTE-170M describes the color burst as a sine wave, whereas the NES outputs a square (or triangle?) wave. If the square-wave 3.58 MHz signal is filtered into a sine-wave, its peak-to-peak amplitude would be larger, but by how much?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Sat Aug 24, 2013 1:21 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2013-08-24T12:53:51-07:00</updated>
<published>2013-08-24T12:53:51-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117002#p117002</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117002#p117002"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117002#p117002"><![CDATA[
<div class="quotetitle">NewRisingSun wrote:</div><div class="quotecontent"><br /><div class="quotetitle">Drag wrote:</div><div class="quotecontent">R, G, and B each have their own independent gamma curves, but you'd never know if you asked anyone because everyone wants you to apply gamma only to the luminance<br /></div>There is not a single television standard document that ever calls for R/G/B having different electro-optical transfer characteristics.</div><br />Gamma correction applies only to an all-positive signal. The common practice in digital video editing in the YCbCr (YUV) domain is to gamma-correct only the Y channel. But in RGB, yes you're supposed to gamma correct all three.<br /><br />My guess for the phase error is slew rate. There's definitely a low-pass characteristic in the net output from the PPU. Some designs of amplifier have a &quot;slope overload&quot; characteristic, which produces more phase delay at high amplitudes than at low amplitudes because the overall rate of change in voltage over time has limits. There's a difference between this limit and impedance that depends on voltage: impedance that depends on voltage would affect the lower-frequency luma signal, while slew rate mostly affects chroma. There's a test for this: the chroma component of $08 or $38 has a larger amplitude than colorburst, and the chroma component of $18 or $28 has an even larger amplitude. If there's more phase delay on $18 and $28 than on $08 and $38, you've found your culprit.<br /><br />And since 2006, there's been a standard for how to handle out-of-gamut colors: <a href="https://en.wikipedia.org/wiki/XvYCC" class="postlink">xvYCC</a>.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sat Aug 24, 2013 12:53 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2013-08-24T13:00:35-07:00</updated>
<published>2013-08-24T12:35:37-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117000#p117000</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117000#p117000"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=117000#p117000"><![CDATA[
<div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />If colorburst is phase 8, why does the on-screen color not have the greenish-yellow colorburst hue?<br /></div>It has on the Sharp AN-500B Twin Famicom. The Sharp AN-505BK Twin Famicom looks even more greenish (positive hue shift, about +10°). I've never had a US NES, but all video captures seem to indicate a negative hue shift (about -10°), making on-screen color #8 look less greenish. All this on the same TV. On a different TV, the AN-500B looks just as greenish as the AN-505BK. The reason seems to be that the NES does not properly output a sine wave for the color burst but some sort of <a href="http://forums.nesdev.com/viewtopic.php?t=10101" class="postlink">weird filtered triangle wave</a>, which causes further variation across models and television sets. <br /><br />The PAL NES on the other hand has rock-solid (i.e. constantly washed-out) colors across all sets I've seen.<div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />R, G, and B each have their own independent gamma curves, but you'd never know if you asked anyone because everyone wants you to apply gamma only to the luminance<br /></div>There is not a single television standards document that ever calls for R/G/B having different electro-optical transfer characteristics.<div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />especially in the darker $0x-$1x range of the palette<br /></div>Those colors are very much affected by how you assume your emulated TV handles non-standard video levels, in particular, the NES' too-small sync amplitude. Also try both 0 and 7.5% black-level setup. These are more likely sources of variation than putative gamma curves. <br /><br />Consider the following ways of interpreting the NES' video signal --- all valid methods found in models of TV capture cards and television sets, see attached pictures. I could post another threesome of pictures for NTSC-J with 0% black-level setup. (All pictures use a -13° hue shift from color 8, and no NTSC-&gt;sRGB color correction).<div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />it doesn't seem like anyone's legitimately interested in a palette that resembles a physical CRT's color output.<br /></div>That's what I've been doing for the past 8 years or so...<div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />Moreover, what's the correct way to deal with out-of-gamut colors (which the NES is fond of producing, especially in the blues)<br /></div>No television standards document mentions a correct way of doing so, assuming that with proper receiver adjustment, you just get the same R/G/B values that originated in the hypothetical television camera. You can either just clip at 0 and 255, or reduce saturation for that color until none clip.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Sat Aug 24, 2013 12:35 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Drag]]></name></author>
<updated>2013-08-23T23:22:29-07:00</updated>
<published>2013-08-23T23:22:29-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116983#p116983</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116983#p116983"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116983#p116983"><![CDATA[
<div class="quotetitle">lidnariq wrote:</div><div class="quotecontent"><br /><div class="quotetitle">NewRisingSun wrote:</div><div class="quotecontent">Has it been confirmed that color burst is always at the same phase as color $8?<br /></div>In the digital domain, it's definitely always phase $8, and there's no ability to specify anything other than some multiple of 30°.</div><br /><br />I will repeatedly say this over and over until I understand: If colorburst is phase 8, why does the on-screen color not have the greenish-yellow colorburst hue? It <em>really</em> looks like it should be color 9 and not color 8. Every single NTSC color generator matrix/formula/whatever I've used, with NES parameters plugged in (including forcing color 8 to be the literal colorburst hue) just <em>does not</em> produce results that look like anything I've ever seen the NES look like, even if I set color 9 to be the colorburst hue, it still doesn't look right unless I shift the hues slightly, which screws up other colors. Moreover, there's things like gamma curves (R, G, and B each have their own independent gamma curves, but you'd never know if you asked anyone because everyone wants you to apply gamma only to the luminance, which doesn't produce the right colors, especially in the darker $0x-$1x range of the palette) to worry about too, and really, it doesn't seem like anyone's legitimately interested in a palette that resembles a physical CRT's color output. Moreover, what's the correct way to deal with out-of-gamut colors (which the NES is fond of producing, especially in the blues)?<br /><br />So this is basically why I completely gave up on this. <img src="http://forums.nesdev.com/images/smilies/icon_razz.gif" alt=":P" title="Razz" /><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=21">Drag</a> — Fri Aug 23, 2013 11:22 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2013-08-10T10:04:43-07:00</updated>
<published>2013-08-10T10:04:43-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116308#p116308</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116308#p116308"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116308#p116308"><![CDATA[
Is the master clock input exactly 50% duty? If not, that might mess with the phase generator, causing the odd phases ($9, $B, $1, $3, $5, $7) to be offset.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sat Aug 10, 2013 10:04 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[lidnariq]]></name></author>
<updated>2013-08-09T22:33:17-07:00</updated>
<published>2013-08-09T22:33:17-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116299#p116299</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116299#p116299"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116299#p116299"><![CDATA[
<div class="quotetitle">NewRisingSun wrote:</div><div class="quotecontent"><br />Has it been confirmed that color burst is always at the same phase as color $8? I'm asking because of the several Famicom and Twin Famicom consoles I have, each outputs colors with a slightly different hue shift. In particular, while the -G 2C02 revision seems to place burst at color 8 +/- 0 degrees, the -H 2C02 (in a AN-505BK Twin Famicom) seems to output burst at 8 -10 degrees, equivalent to a palette setting of +10 degrees, which is very greenish.<br /></div>In the digital domain, it's definitely always phase $8, and there's no ability to specify anything other than some multiple of 30°. Whether subsequent analog effects skew the phase afterwards is something still under discussion. ( e.g. <!-- l --><a class="postlink-local" href="http://forums.nesdev.com/viewtopic.php?t=10101">viewtopic.php?t=10101</a><!-- l --> )<br /><br />As far as I've been able to tell from the discussions, it really looks like there shouldn't be an appreciable phase error between colorburst and other voltages. Due to the common collector amplifier that's certainly present in the NES, and in the schematic for the Famicom, the output impedance shouldn't vary appreciably by output voltage.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=3512">lidnariq</a> — Fri Aug 09, 2013 10:33 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2013-08-09T13:04:33-07:00</updated>
<published>2013-08-09T13:04:33-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116287#p116287</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116287#p116287"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116287#p116287"><![CDATA[
Has it been confirmed that color burst is always at the same phase as color $8? I'm asking because of the several Famicom and Twin Famicom consoles I have, each outputs colors with a slightly different hue shift. In particular, while the -G 2C02 revision seems to place burst at color 8 +/- 0 degrees, the -H 2C02 (in a AN-505BK Twin Famicom) seems to output burst at 8 -10 degrees, equivalent to a palette setting of +10 degrees, which is very greenish.<br /><div class="quotetitle">psycopathicteen wrote:</div><div class="quotecontent"><br />Some machines even use 1.5Mhz for U and V<br /></div>Yes, that's what SMPTE 170M &quot;Composite Analog Video Signal - NTSC for Studio Applications&quot; calls for.<div class="quotetitle">psycopathicteen wrote:</div><div class="quotecontent"><br />which is pretty stupid since you are left with only 2Mhz of Y bandwidth<br /></div>Not with a notch or comb filter.<div class="quotetitle">psycopathicteen wrote:</div><div class="quotecontent"><br />and both color axis have a cropped upper sideband, due to the 4.2Mhz channel limit<br /></div>... which doesn't exist in studio applications. (Leaving me to wonder what a broadcast TV station does when playing back a composite studio tape --- just crop the upper sideband, or decode and reencode with narrowband color difference signals before transmission?)<br /><br />Edit: found the answer myself.<div class="quotetitle">SMPTE EG 27 wrote:</div><div class="quotecontent"><br />When this signal is transmitted, a low-pass filter in the transmitter bandwidth limits the luminance (Y) signal and the upper sidebands of the color-difference signals (either B-Y and R-Y or I and Q) to 4.2 MHz. Transmission of equal-bandwidth color-difference signals to the receiver has the effect of limiting the recoverable chroma bandwidth to 0.6 MHz as a result of the truncation of the upper sidebands of the chroma modulation in the transmitter’s 4.2 MHz filter.<br /></div><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Fri Aug 09, 2013 1:04 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[psycopathicteen]]></name></author>
<updated>2013-08-09T08:54:08-07:00</updated>
<published>2013-08-09T08:54:08-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116276#p116276</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116276#p116276"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116276#p116276"><![CDATA[
<div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />For now, I've updated the palette generator. Some of the new tweak settings are from suggestions. The hue was me, because even though a hue tweak of 0.0 should represent the exact hues being sent, it still doesn't look right unless I shift them by -0.15. Your mileage may vary.<br /></div><br /><br />I agree.  With the color burst being at $x8, there is no red.  Just pink and orange, with nothing in between.<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />The main difference between YUV and true YIQ decoding is that with the latter, the I signal is assumed to occupy a 1.5 MHz bandwidth (Q a 0.5 MHz bandwidth), whereas with YUV decoding, both are assumed to occupy a 0.5 MHz bandwidth. Unless you are decoding with different bandwidths for I and Q, you are not truely doing YIQ decoding, but merely &quot;rotated YUV&quot; decoding.<br /></div><br /><br />Some machines even use 1.5Mhz for U and V which is pretty stupid since you are left with only 2Mhz of Y bandwidth, and both color axis have a cropped upper sideband, due to the 4.2Mhz channel limit.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=4383">psycopathicteen</a> — Fri Aug 09, 2013 8:54 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[NewRisingSun]]></name></author>
<updated>2013-08-06T10:42:13-07:00</updated>
<published>2013-08-06T10:42:13-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116100#p116100</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116100#p116100"/>
<title type="html"><![CDATA[Re: Emulator palettes vs real NTSC TVs]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=7261&amp;p=116100#p116100"><![CDATA[
<div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />What does it mean to say that something &quot;uses&quot; a particular color space?<br /></div>The NES uses a particular color space in the sense that if the PPU engineer assumed that the displaying CRT used NTSC phosphors, he would have chosen resistors for the color-signal-generating resistor ladder that produce a lower saturation level than if he assumed that the displaying CRT used SMPTE-C phosphors.<br /><div class="quotetitle">Drag wrote:</div><div class="quotecontent"><br />Even if modern TVs use YUV decoders, YIQ and YUV are the same, the only difference is that YIQ's axis is rotated slightly.<br /></div>The main difference between YUV and true YIQ decoding is that with the latter, the I signal is assumed to occupy a 1.5 MHz bandwidth (Q a 0.5 MHz bandwidth), whereas with YUV decoding, both are assumed to occupy a 0.5 MHz bandwidth. Unless you are decoding with different bandwidths for I and Q, you are not truely doing YIQ decoding, but merely &quot;rotated YUV&quot; decoding.<br /><div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br />Can you elaborate on this? All I can think of is gamma. Does it display say rgb[FF,00,00] the same, and rgb[00,AA,00] the same, but not when combined? I know there was talk here many years ago about TVs doing some adjustment of hues in the skin-tone range of hues.<br /></div>Television sets differ in many ways other than gamma. They differ at least also in<br /><ul><li>phosphor chromaticities (&quot;So what does 100% red look like?&quot;)</li><li>white point (&quot;What does 100% white look like?&quot;)</li><li>behavior with out-of-spec signals.</li></ul>The first two points define the color space. Three hexadecimal RGB values say nothing about how a color actually looks until you specify a color space. If none is specified, modern systems assume sRGB. The last point is of particular importance for home computers and consoles. Signals can be out-of-spec with regards to <ul><li>the peak-to-peak signal level</li><li>the sync level relative to blanking level</li><li>the white level relative to blanking and/or sync</li><li>the color burst amplitude</li><li>oversatured red/green/blue levels after decoding</li></ul>In the case of the NES, pretty much everything except the peak-to-peak signal level is wrong. <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /> Since the NTSC standard does not define how to deal with non-standard signals, this should be the greatest source of variation between different television sets and computer images. In particular, an analogue CRT can be expected to react very differently to a &gt;100% red/green/blue signal than a digital device (which will probably just clip).<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=133">NewRisingSun</a> — Tue Aug 06, 2013 10:42 am</p><hr />
]]></content>
</entry>
</feed>