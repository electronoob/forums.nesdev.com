<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-gb">
<link rel="self" type="application/atom+xml" href="http://forums.nesdev.com/feed.php?f=3&amp;t=1309" />

<title>nesdev.com</title>
<subtitle>NES Development and Strangulation Records message boards</subtitle>
<link href="http://forums.nesdev.com/index.php" />
<updated>2006-04-19T18:42:23-07:00</updated>

<author><name><![CDATA[nesdev.com]]></name></author>
<id>http://forums.nesdev.com/feed.php?f=3&amp;t=1309</id>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-04-19T18:42:23-07:00</updated>
<published>2006-04-19T18:42:23-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12073#p12073</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12073#p12073"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12073#p12073"><![CDATA[
<div class="quotetitle">ReaperSMS wrote:</div><div class="quotecontent"><br />Exceptions are the spawn of satan, but when you *need* them, implementing them any other way is even worse.<br /></div><br />Damn right.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Wed Apr 19, 2006 6:42 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2006-04-18T19:25:01-07:00</updated>
<published>2006-04-18T19:25:01-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12050#p12050</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12050#p12050"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12050#p12050"><![CDATA[
<div class="quotetitle">laughy wrote:</div><div class="quotecontent"><br />since a decent computer will run any nes emulator out there anyway.<br /></div><br />"Decent computers" are too large to fit in one's pocket. Emulation speed freaks can still target handheld platforms such as Nintendo DS, PSP, Windows Mobile, J2ME phones, and the like.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Tue Apr 18, 2006 7:25 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[laughy]]></name></author>
<updated>2006-04-18T19:18:55-07:00</updated>
<published>2006-04-18T19:18:55-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12048#p12048</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12048#p12048"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=12048#p12048"><![CDATA[
Although speed is important, the presence of clean, manageable code is worth a lot of points in my book. My emulator is pretty object oriented, and new features, bug fixes, etc. are a snap. It is still <em>very</em> fast. Frankly I think nes emulators should tend towards improving the emulation experience (graphic filtering, features, GUI, etc.) for the user, since a decent computer will run any nes emulator out there anyway.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=50">laughy</a> — Tue Apr 18, 2006 7:18 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[ReaperSMS]]></name></author>
<updated>2006-04-04T18:36:40-07:00</updated>
<published>2006-04-04T18:36:40-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11560#p11560</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11560#p11560"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11560#p11560"><![CDATA[
The issue with templates is that excessive use of them can hide huge amounts of complexity that effectively hamstring the optimizer. They also tend to increase compile times -- there's a library here that doubles the compile time of any project it's included in, and drags the runtime speed without optimization down to about 3 fps. It's been known to devour babies.<br /><br />That said, templates are a really wonderful tool, for the reasons you mentioned.<br /><br />baisoku: you are not *quite* correct, gcc and g++ are merely compiler drivers, choosing which of cc1 and cc1plus to run. cc1plus is, of course, the C++ compiler, and has a completely different frontend. The machine specific backend is identical between the two, but language semantics differ enough now that there are some subtle differences in the code generation for nominally identical chunks of code.<br /><br />What ends up confounding compilers is usually excessively inlined functions (a prime source of debug pain, since inlining is usually disabled without -O1 at the very least) and excessive reliance on dead code elimination and constant propogation. The language semantics will get in your way at times as well if you're trying to pass extended types around (such as vectors)<br /><br />Exceptions are the spawn of satan, but when you *need* them, implementing them any other way is even worse.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=8">ReaperSMS</a> — Tue Apr 04, 2006 6:36 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2006-04-03T22:21:44-07:00</updated>
<published>2006-04-03T22:21:44-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11528#p11528</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11528#p11528"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11528#p11528"><![CDATA[
<div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />I'm not sure how well it handles things like partial specialization--you're making the compiler work at it a bit, but it probably comes up with good code.<br /></div><br /><br />Partial specialization is a compile-time thing; it would be pretty difficult for a compiler to implement it in a way that generated any run-time structures at all. Same for templates entirely (and one of the two reasons for templates existing, the other being type-safety).<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />As far as this bit goes -- my wild-ass guess is that g++ does a good enough job at optimizing templates. You can probably use them with impunity and not get penalized.<br /></div><br /><br />Don't muddle the language feature with the STL library (sorry if this seems critical of you, I just hear the "templates are slow, C++ is slow" kind of babble too often). There isn't any such thing as optimizing templates; the only optimization a compiler does is on code. A template is not code; it generates code, and by very strict rules. If a compiler's template machinery isn't broken, it will generate the same intermediate code as any other non-broken compiler's template machinery. The STL, on the other hand, is a library of templates for algorithms and data structures. The interface of the STL is standardized, but the implementation is up to the compiler, and each compiler's is usually different. I've used a lot of bad STL implementations over the years, but this has nothing to do with the language feature of templates, so on these compilers I've always been able to write my own class and function templates without any overhead as compared to hand-crafted code. Language features in general have no unnecessary costs, even on bad compilers, while the standard library implementation on a bad compiler can be horrendously inefficient and bloated.<br /><br />The "embedded C++" people couldn't make this distinction (and on other fronts too) and needlessly eliminated features that can be used to make to smaller, faster programs, due to the ability to implement better designs for the same cost. In general, every language feature is an automated form of some equivalent hand-crafted code, and like any automaton, can make a mess if you send it off making a bunch of unnecessary things.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Mon Apr 03, 2006 10:21 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[baisoku]]></name></author>
<updated>2006-04-03T21:16:47-07:00</updated>
<published>2006-04-03T21:16:47-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11526#p11526</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11526#p11526"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11526#p11526"><![CDATA[
<div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />I think gcc and g++ use the same back end, so the question is, if you use a certain C++ construct, will the front end and/or the optimizer parts, be able to turn it into something equivalent to what the C compiler would have produced on morally equivalent C code?  When you inline a method, that is as good as using a macro in C.<br /></div><br />g++ and gcc are essentially identical. g++ just invokes gcc with some silent options. Everything you get with gcc you get with g++.<br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />Most uses of templates are probably safe.  I'm not sure how well it handles things like partial specialization--you're making the compiler work at it a bit, but it probably comes up with good code.<br /></div><br />The concepts of partial specialization and template code that is deemed "difficult" for the compiler to digest are really ones that are a step or few abstracted from the mechanics of code optimization. The idea behind template metaprogramming and other similar techniques is to shift work from the run-time to the compile-time phase. Ten years ago when C was the staple, we would shift work from the run-time to the preprocessing phase. Ten years before that, we'd make a lookup table <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" />, which was effectively shifting program A's runtime to some infrequently run program B.<br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />RTTI and exceptions I would just avoid.<br /></div><br />Exceptions are difficult to work with, and not very well supported in C++. They are hard to use effectively in real-time systems, but are often very useful in data-processing tools; offline converters and such. They're hard to retrofit into systems; it's similar to taking a legacy codebase and attempting to make it const-correct. If it's done from the start, things fall into place, but once the architecture is laid, there's a cascade of irritating changes that need to be made throughout the entire system. Best to just rewrite it. (or stay away from exceptions altogether <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /><br />The last handheld game project i worked on shipped with RTTI enabled. It wasn't used heavily, and what it was used for could have been done in other ways, but judicious use of it can be extremely helpful. It's one of those spooky handwavy features that people stay away from in general and its negatives get amplified in the absence of application; sort of like your first experience with source control tools automatically merging check-in conflicts.<br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />Traditionally gcc is not the best at optimizing on x86 (where the Microsoft compiler might produce 10% faster code, and the Intel compiler might produce slightly faster--though larger--code than Microsoft's).  They've been improving the optimizer in gcc/g++ over the last few years, but optimizing well for x86 is challenging because x86 has so few general registers, and modern x86 CPUs are pretty complicated to compensate for this.  For non-x86 chips (especially popular ones like PPC and Sparc), I would guess that gcc is probably as good as anything else.<br /></div><br />gcc has been inferior in my tests (admittedly a few years ago) on x86 architectures; the last rev i worked with was 2.9x. I'm not sure how the new 3.x and 4.x codelines fare, but i would expect them to be somewhat better. The problem does seem to be the excruciatingly small register file on x86.<br />In my experience, gcc really shines on RISC architectures. Our first PSP title built on a relatively expensive commercial compiler. After we shipped, i spent a couple of days getting it building under the run-of-the-mill port of gcc 3.3 that comes along with the SDK. To my amazement, i got an instant 15-20% performance improvement-- just from a recompile. This project was pretty standard C++ with heavy use of the STL. gcc's code generation was *much* better than the other guys. My faith in gcc was restored, tenfold.<br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />If you are worried about a certain feature, keep in mind you can get the compiler to spit out an assembly listing and then look at it and see if there's any obvious suckitude in it.  <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" />  This is easiest if you can isolate the thing you want to check into a tiny program by itself---then you can write an equivalent tiny program in C and compare the two listings and see if the C++ compiler did a comparatively bad job or not.<br /></div><br />Of course, this gets harder as time goes on and current-gen architectures become less dependent on cpu instruction counts and more dependent on cache behavior, bus bandwith, and pipelining. Reading the asm can be misleading sometime.<br />Tangentially, does anyone know of any good, free cache profiling tools for Windows/x86, other than vtune? Sadly, valgrind is only available on linux.<br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />As far as this bit goes -- my wild-ass guess is that g++ does a good enough job at optimizing templates.  You can probably use them with impunity and not get penalized.  At least as good as any other C++ compiler I can think of---the Microsoft compiler was weak in that area a few years ago (it would choke on certain complex template things in the STL, for example).  Maybe they have improved it, but I don't know.  I haven't used Microsoft's compiler for a few years.<br /></div><br />.NET 2003 seems much better than vc6. gcc's standards compliance is excellent at this point. Templates are a great tool for your C++ toolbox. As with any well-honed tool, improper use will result in disaster. You can easily bloat your codespace by using them without discipline, and you probably want to stay away from reading your ROM images in byte-by-byte and jamming them into a std::vector... <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=35">baisoku</a> — Mon Apr 03, 2006 9:16 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-04-03T17:13:57-07:00</updated>
<published>2006-04-03T17:13:57-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11520#p11520</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11520#p11520"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11520#p11520"><![CDATA[
<div class="quotetitle">Josh wrote:</div><div class="quotecontent"><br />Thanks for the detailed analysis, mozz.<br /><br />You mentioned the importance of a good optimizing compiler with more intricate C++ constructs. Is gcc (specifically, the newer versions of MinGW) considered good at optimizing code?<br /></div><br />Hmm, I don't know.  Its been a few years since I used C++ for anything real.  A recent gcc with mingw is what I would use though--I don't like Microsoft's C++ compiler very much and Intel's tries to be like Microsoft's.  And gcc is free which is very cool.<br /><br />I think gcc and g++ use the same back end, so the question is, if you use a certain C++ construct, will the front end and/or the optimizer parts, be able to turn it into something equivalent to what the C compiler would have produced on morally equivalent C code?  When you inline a method, that is as good as using a macro in C.  Most uses of templates are probably safe.  I'm not sure how well it handles things like partial specialization--you're making the compiler work at it a bit, but it probably comes up with good code.  RTTI and exceptions I would just avoid.<br /><br />Traditionally gcc is not the best at optimizing on x86 (where the Microsoft compiler might produce 10% faster code, and the Intel compiler might produce slightly faster--though larger--code than Microsoft's).  They've been improving the optimizer in gcc/g++ over the last few years, but optimizing well for x86 is challenging because x86 has so few general registers, and modern x86 CPUs are pretty complicated to compensate for this.  For non-x86 chips (especially popular ones like PPC and Sparc), I would guess that gcc is probably as good as anything else.<br /><br />If you are worried about a certain feature, keep in mind you can get the compiler to spit out an assembly listing and then look at it and see if there's any obvious suckitude in it.  <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" />  This is easiest if you can isolate the thing you want to check into a tiny program by itself---then you can write an equivalent tiny program in C and compare the two listings and see if the C++ compiler did a comparatively bad job or not.<br /><br />In the end its not worth worrying about too much.  I would use C++, use gcc and just avoid doing anything excessively bad like using virtual methods for every bytecode dispatch or every emulated memory access.<br /><div class="quotetitle">babbling mozz wrote:</div><div class="quotecontent"><br />Now, if you have a good optimizing C++ compiler, you can even use more advanced C++ features---such as templates and partial template specialization---without taking a performance hit. However, if your compiler is not so good at optimizing, then those features will start to cost you.<br /></div><br />As far as this bit goes -- my wild-ass guess is that g++ does a good enough job at optimizing templates.  You can probably use them with impunity and not get penalized.  At least as good as any other C++ compiler I can think of---the Microsoft compiler was weak in that area a few years ago (it would choke on certain complex template things in the STL, for example).  Maybe they have improved it, but I don't know.  I haven't used Microsoft's compiler for a few years.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Mon Apr 03, 2006 5:13 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Josh]]></name></author>
<updated>2006-04-01T23:28:29-07:00</updated>
<published>2006-04-01T23:28:29-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11475#p11475</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11475#p11475"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11475#p11475"><![CDATA[
Thanks for the detailed analysis, mozz.<br /><br />You mentioned the importance of a good optimizing compiler with more intricate C++ constructs. Is gcc (specifically, the newer versions of MinGW) considered good at optimizing code?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=110">Josh</a> — Sat Apr 01, 2006 11:28 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mattmatteh]]></name></author>
<updated>2006-04-01T22:57:35-07:00</updated>
<published>2006-04-01T22:57:35-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11474#p11474</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11474#p11474"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11474#p11474"><![CDATA[
agreed.<br /><br />and i find the best way to determine the fastest code is to benchmark it your self and use profiling tools such as valgrind.  they can show what line of code is a cach miss.  as i posted already i found a cach miss and removed it.  got alot of speed from fixing it.<br /><br />matt<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=170">mattmatteh</a> — Sat Apr 01, 2006 10:57 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-04-01T13:32:37-07:00</updated>
<published>2006-04-01T13:32:37-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11450#p11450</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11450#p11450"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11450#p11450"><![CDATA[
<div class="quotetitle">tepples wrote:</div><div class="quotecontent"><br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent">For example:  if you changed your CPU dispatch loop to use a table lookup and a virtual method call instead of a switch statement--that would be stupid.  It would probably be twice as slow or something.  <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" /><br /></div><br />Except don't C compilers emit that kind of code for a big @$$ switch statement?</div><br />Most C compilers (and C++ compilers) will examine the values of your case labels and recognize that they're pretty densely packed.  They will generate a range check or two, followed by a table lookup and an indirect branch.  I'm not sure if any compilers are even clever enough to avoid the range check if you switch on a byte-sized variable and include cases for every value the variable can take---I have heard of people using GCC to generate assembly source code and then running their own filtering tool over the assembly to patch out the unnecessary range check, for a little extra speed.<br /><br />On the other hand if you look up a table of 256 objects and then make a virtual method call on them... there would be TWO table lookups (the second one being the vtable lookup for the virtual function call).  The index of the second table lookup is always the same.  You can think of the virtual function call cost as two extra pointer dereferences before the indirect branch--one to get the vtable and another to get the function address out of the vtable slot.  At any rate, you're now reading 3 addresses instead of one before the indirect branch.  It's a longer dependency chain and greater likelihood of an L1 cache miss.<br /><br />Another thing to consider is that with a switch statement, the compiler is optimizing the code of the entire function at once (including each case of the switch).  For example, it can put variables in registers and do intraprocedural optimizations across the dispatch part of the switch.  If you used a virtual method call to do the dispatch, it could not optimize like that.  So overall, I think it would definitely be slower than a switch statement.<br /><br />A handy rule of thumb is to think of memory accesses as being 10x slower than everything else (unless you have good reason to believe they will hit the L1 cache).  The other common thing that slow is mispredicted branches.  When looking at a branch instruction, ask yourself if it is highly predictable, or not?  If it is, it will be cheap (typically one cycle).  If it isn't, it will usually be mispredicted, causing a pipeline flush and wasting tens of cycles.<br /><br />In the past, it was often worth pre-calculating certain stuff into a table and replacing the calculations with a memory lookup.  On today's modern machines, the amount of calculation you can do in the same time as an L2 cache miss is surprising!  Memory accesses are often the bottleneck.  It's worth going out of your way to avoid having large lookup tables of values if you could just compute the values on the fly with a handful of instructions.  Even if it takes you 15 instructions to compute the value, thats still probably faster than a memory lookup that misses the cache.<br /><br />Edit: I forgot to mention, there's another reason to avoid big lookup tables: not only will you likely be looking up values that were not in the cache (causing a cache miss), but the lookup then evicts some *other* piece of cached data to make room for your table value.  So you are increasing the likelihood of cache misses somewhere else.  For something like a CPU core this is not a big deal, but something accessing numerous streams of memory at once--say, a PPU renderer--might suffer from this.<br /><br />Sometimes a large lookup table can be simplified into a much smaller table plus a small amount of calculation.  For example, the chess engine Crafty uses (or used to, anyway, I haven't looked for years) a set of bitboard tables that were something like 256K.  I developed an x86-specific technique that accomplished the same thing, except it used a handful of extra bit-scan instructions.  With the aid of the bit-scan instructions I was able to shrink the table to 2,560 bytes, and lookups in the reduced table were about 100 times more likely to hit the cache (besides which, the entire table could now fit easily in the L1 cache).  <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" /><br /><br />What sort of tables tend to be large in an emulator?  Well, the dispatch table for 256 opcode bytes is 1K.  If your CPU core was written in assembly you could try to shrink that table, but that may be a waste of time.  What about caches of graphics tiles?  I know SNES emulators typically cache the tiles in a form that is easier to render, and the cache can be kinda big.  Lookup tables for graphics filters are also good candidates.  (Unfortunately its often hard to shrink those kind of tables without increasing the needed number of lookups...)<br /><br />But anyway, to get back on topic... C++ can be fast but unless you learn the language thoroughly and understand how the compiler implements the language constructs, its easy to shoot yourself in the foot with it, performance-wise.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Sat Apr 01, 2006 1:32 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2006-04-01T13:18:38-07:00</updated>
<published>2006-04-01T13:18:38-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11448#p11448</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11448#p11448"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11448#p11448"><![CDATA[
The compiler I use emits a binary search when the number of cases is small (8 or so), then switches to a table for large cases. That is the single biggest performance bottleneck in my NES emulator, taking about 12% of emulation time dispatching the switch (which isn't helped by my compiler's stupid implementation that stalls the pipeline). I've tried adding a few if statements for the most common instructions (before the switch), but that didn't help.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Sat Apr 01, 2006 1:18 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2006-04-01T12:08:15-07:00</updated>
<published>2006-04-01T12:08:15-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11446#p11446</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11446#p11446"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11446#p11446"><![CDATA[
<div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />For example:  if you changed your CPU dispatch loop to use a table lookup and a virtual method call instead of a switch statement--that would be stupid.  It would probably be twice as slow or something.  <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" /><br /></div><br />Except don't C compilers emit that kind of code for a big @$$ switch statement?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sat Apr 01, 2006 12:08 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[WedNESday]]></name></author>
<updated>2006-04-01T11:49:48-07:00</updated>
<published>2006-04-01T11:49:48-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11445#p11445</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11445#p11445"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11445#p11445"><![CDATA[
<div class="quotetitle">mozz wrote:</div><div class="quotecontent"><br />Since I've used C and C++ for a long time, here's my own 2 cents about this issue.<br /></div><br /><br />2 cents? That was more like 50 bucks.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=191">WedNESday</a> — Sat Apr 01, 2006 11:49 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-04-01T11:18:37-07:00</updated>
<published>2006-04-01T11:18:37-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11443#p11443</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11443#p11443"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11443#p11443"><![CDATA[
Since I've used C and C++ for a long time, here's my own 2 cents about this issue.<br /><br />It's possible to use C++ as if it were C with a few extra nice features (such as being able to declare variables in the middle of your methods).  If you do that, the performance is about the same.<br /><br />It's also possible to use C++ as if it were "C with classes"---i.e. turn your structs into classes and convert your functions which manipulate those classes, into methods of the class.  As long as they are not virtual methods, the performance should be the same.<br /><br />Its even possible to use C++ as "C with classes and lots of inline methods"---i.e. instead of directly accessing the fields of a struct, you can create accessor methods which give you better encapsulation and keep the complexities in one place.  Think of inline methods as being sort of like typesafe macros---semantically they are just like other methods, but the compiler will expand them inline at the call sites and then be able to optimize that code as well as if you had used a macro.  The key thing is that once the compiler expands the code inline, it can optimize it as if it were part of the enclosing function.<br /><br />Now, if you have a good optimizing C++ compiler, you can even use more advanced C++ features---such as templates and partial template specialization---without taking a performance hit.  However, if your compiler is not so good at optimizing, then those features will start to cost you.<br /><br />You see, the C language is simple enough to compile that most C compilers can do a decent job of compiling and optimizing nearly any C code.  But the C++ language, by its nature, <strong>relies on a good optimizing compiler</strong> to achieve the kind of good performance that C programs achieve.  This is good in some ways--it allows you to write higher-level code, with better abstractions, making it more object-oriented, etc. and still have good performance.  It's a bad thing in other ways--C++ compilers are slower, extremely complex and difficult to write, and thus less widely available (though I think g++ is available on all the platforms gcc is available on).<br /><br />C++ offers a large library (the STL, or Standard Template Library) which has good, generic implementations of containers (hash tables, maps, vectors, lists, strings of characters, streams, etc) and algorithms (searching, sorting, etc).  It is often a lot easier to use these than to code all that stuff yourself (and it may even perform better since the STL implementations are highly optimized).  Be aware that using lots of templated code in your program (such as several different specializations of STL container classes) can cause code bloat, making your executable rather large.  Most people (including emu authors!) don't seem to care about that these days, but keep in mind that every extra 4K in your executable code is another page the operationg system might have to load from disk, page out when it seems to no longer be part of the working set, etc.  Keeping things small has some advantages.<br /><br />C++ also includes features that you should stay away from if you're writing low-level, performance-sensitive programs.  Things like RTTI and exception handling, and multiple inheritance with virtual base classes.  If you enable those features, they will slow things down somewhat.  <br /><br />Even though virtual methods are a cornerstone of polymorphism in C++, you should be careful about their use in performance-critical code.  Overusing virtual methods will slow things down somewhat---every time you make a call to a virtual method, imagine that you were instead dereferencing a pointer into a function table array and then calling a function through a function pointer.  Cause that's basically what you're doing.<br /><br />In summary:  If you know C, you can use C++ as a "better C" and use only a few of its features and it will be just as good as using C.  You can even use the more advanced features of C++ and still get the same performance as C (or even better performance in some specific cases---if you were hard-coding a bunch of linear algebra calculations, template metaprogramming might yield faster code than anything you could directly express in C).  But if you are going to fully embrace C++, you have to learn what features are cheap or "free" (thanks to compiler optimizations) and what features will potentially slow down your program.<br /><br />For example:  if you changed your CPU dispatch loop to use a table lookup and a virtual method call instead of a switch statement--that would be stupid.  It would probably be twice as slow or something.  <img src="http://forums.nesdev.com/images/smilies/icon_wink.gif" alt=":wink:" title="Wink" /><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Sat Apr 01, 2006 11:18 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2006-03-31T17:42:35-07:00</updated>
<published>2006-03-31T17:42:35-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11433#p11433</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11433#p11433"/>
<title type="html"><![CDATA[C/C++ speed differences]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=1309&amp;p=11433#p11433"><![CDATA[
<div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />It sounds like the speed hit would be negligible for most of what I had in mind.<br /></div><br /><br />What are you comparing the speeds of here?<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />However, this might still result in a speed hit, since some MMC routines might need to be called each clock cycle (many mappers use M2-based counters).<br /></div><br /><br />A design which requires calling a function every clock cycle is going to incur a performance penalty no matter how you code it. If you're taking this approach, I'd recommend using custom dispatch for these operations. They wouldn't be good candidates for a virtual call because they'd be doing little more than modifying a counter and seeing if it reached a certain value. You could even code up a generic "increment/decrement X until it reaches the value Y, then call another function" that each MMC could configure appropriately. This is an example of removing the need for polymorphism by finding a one-size-fits-all set of behavior. It might do a little more than some mappers need, but this inefficiency is more than offset by the lack of having to select behavior at run-time.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Fri Mar 31, 2006 5:42 pm</p><hr />
]]></content>
</entry>
</feed>