<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-gb">
<link rel="self" type="application/atom+xml" href="http://forums.nesdev.com/feed.php?f=3&amp;t=547" />

<title>nesdev.com</title>
<subtitle>NES Development and Strangulation Records message boards</subtitle>
<link href="http://forums.nesdev.com/index.php" />
<updated>2006-07-03T10:19:10-07:00</updated>

<author><name><![CDATA[nesdev.com]]></name></author>
<id>http://forums.nesdev.com/feed.php?f=3&amp;t=547</id>
<entry>
<author><name><![CDATA[byuu]]></name></author>
<updated>2006-07-03T10:19:10-07:00</updated>
<published>2006-07-03T10:19:10-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14979#p14979</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14979#p14979"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14979#p14979"><![CDATA[
Actually, a single DMA call can span over eleven fields (consider it frames in non-interlace).<br /><br />8 channels * 65536 bytes/channel * 8 clocks/byte transferred = 4194304 clocks<br />1364 clocks/scanline * 262 lines/field = 357368 clocks/field<br />4194304 / 357368 = 11.7 fields<br /><br />Anyway, I'm aware that if I can align the CPU and APU on opcode boundaries or "cheat" and execute instructions out of order (so long as they aren't communicating with each other it won't matter), I can save states at "safe" points. But I really wanted to avoid that sort of code trickery if possible. Especially a time buffer. If I have a time buffer between CPU and APU communications, I may as well not use cothreading to begin with. The goal was quite honestly to simplify the code.<br /><br />We're really only talking a single opcode of desynchronization anyway, and even then it can't be detected unles the two are communicating <em>with</em> each other (eg CPU is accessing APU port and APU is accessing CPU port. One or the other would not cause a problem). It's not like other emulators (excepting probably SS) have more accurate savestates anyway ... and this allows conversion between the emulators since they cannot resume mid-opcode.<br /><br />So then :<br /><br /><div class="codetitle"><b>Code:</b></div><div class="codecontent">void save_state&#40;&#41; &#123;<br />  while&#40;r_cpu-&gt;scanline&#40;&#41; &lt; 240 || r_cpu-&gt;scanline&#40;&#41; &gt; 260&#41;snes-&gt;run&#40;&#41;;<br />  while&#40;r_cpu-&gt;in_opcode&#40;&#41;&#41;r_cpu-&gt;run&#40;&#41;;<br />  while&#40;r_apu-&gt;in_opcode&#40;&#41;&#41;r_apu-&gt;run&#40;&#41;;<br />  capture_savestate&#40;&#41;;<br />&#125;</div><br /><br />The only uncertain part left is the PPU. Right now, the PPU does not have its own thread, and runs one scanline at a time. Therefore, I have no re-entry problems with it.<br />However, with a dot-based renderer, things might get more tricky. Taking a snapshot every field may work, but isn't as point-specific as I'm sure some would like. Specifically, romhacking would suffer if the savestate leaped forward when they were testing a small block of code. I would need to make the PPU renderer re-entrant, or force it to "run ahead" to the next "safe point" which I have no idea where that would be at.<br /><br />Lastly, I'm still planning on creating interpretive opcode emulators that can be combined with the current scanline PPU renderer. It should hopefully be as accurate as SNES9x ever will be (but nowhere near as fast) at least, and won't require cothreading at all.<br /><br />And as always, I'm still interested in a <em>transparent</em> way to create recursive re-entrant functions that gets at least 80% of the speed of cothreading, but without actually requiring cothreading.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=375">byuu</a> — Mon Jul 03, 2006 10:19 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[dvdmth]]></name></author>
<updated>2006-07-01T10:18:28-07:00</updated>
<published>2006-07-01T10:18:28-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14916#p14916</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14916#p14916"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14916#p14916"><![CDATA[
Going back a little ways here...<br /><br />byuu - You're looking for a way to do savestates in a co-threaded execution model?  I used co-threads once before, so I'm used to how they work.  I might have a suggestion here, although I don't know how feasible it is, as I don't know how your code is set up.<br /><br />Each of the three emulation threads (CPU, PPU, APU) should have one "safe yield" point where a savestate can be made.  The PPU would most likely have this point during its V-Blank (or forced blank, possibly) handler, since that would be an easy time to resurrect the current state as the PPU isn't really doing anything other than counting cycles.  The CPU and APU would have a "safe yield" between instructions, where execution would return to the main loop within their respective cores.  Upon resuming from a "safe yield," all three threads should receive a message stating whether the thread should archive its state (to a section of memory, pending write to disk) or not.  This way, each thread is responsible for archiving its state.<br /><br />All threads should, upon creation, receive an "unarchive" message, telling it to load to an existing state and jump to the code immediately following the "safe yield" location.  If a save state is loaded, currently executing threads would be destroyed and new threads would be created, so that a thread would not have to test for "unarchiving" after every yield.<br /><br />You should have no trouble syncronizing the PPU and CPU to "safe yield" points, since the CPU should (in most cases) execute numerous instructions during V-Blank.  The tricky part, however, is finding a "safe yield" point for the APU.  My suggestion here is this:  When the user hits the freeze state button/key, continue execution until the CPU and PPU are both at safe yield points, then tell those two threads to archive.  Next, continue execution until the APU is on a safe yield point, then archive its state and write to disk (making sure to include the amount of time elapsed between the CPU/PPU states and the APU state).  When resuming from a savestate, be sure to block APU execution until the appropriate amount of time passes.<br /><br />The only time this will fail is if the CPU reads from an APU register (writes to an APU register won't be a problem, as their effects would be remembered in the APU state).  The way to solve this would be to archive the state of these registers on every CPU read cycle between the CPU state and the APU state, then restoring these values after each cycle when loading the savestate.  Thus, if the CPU ever accesses these registers during this time, it would receive the value returned by the APU at that time.<br /><br />The only remaining problem I can think of would be if DMA takes up the entire V-Blank time, but I don't see how that could happen during gameplay (is it possible?).<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=360">dvdmth</a> — Sat Jul 01, 2006 10:18 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2006-06-29T23:31:38-07:00</updated>
<published>2006-06-29T23:31:38-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14852#p14852</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14852#p14852"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14852#p14852"><![CDATA[
You don't need to worry about your entire code set fitting in the cache, just the often-used portion. For the CPU emulator, for example, a small set of instructions dominate. The same probably goes for what hardware is most accessed, like the PPU status register.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Thu Jun 29, 2006 11:31 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-06-29T22:05:58-07:00</updated>
<published>2006-06-29T22:05:58-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14847#p14847</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14847#p14847"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14847#p14847"><![CDATA[
<div class="quotetitle">byuu wrote:</div><div class="quotecontent"><br />Or more realistically, it'd be kind of cool to try and design the smallest possible NES emulator in pure assembly as a .com DOS file.<br /></div><br />Its a cool idea, but I don't know realistically how small you can make some of the stuff.  The PPU for example---perhaps you could make one that was small or fast but not both.  And I have no idea how small, either--maybe not very.  And then think of the mappers... yikes!  I bet even a clever size-optimized implementation of 100+ mappers will be bigger than my asm core.  <img src="http://forums.nesdev.com/images/smilies/icon_razz.gif" alt=":P" title="Razz" /><br /><br />At the end of the day, if all the important code+tables fits in an L1 cache then that will be good enough.<br /><br />One thing I hope to do with my code generator is experiment a bit.  If my core was 10x bigger but only used one handler per instruction instead of two, would it be faster or slower?  (I suspect it would be a tiny bit faster, but truly I am just guessing!)  But I have lots to do before I get to that point (start compiling and debugging these cores, get generating a suite of automated instruction tests and get the cores running those tests, etc).<br /><br />Edit: also my code is meant for 32-bit code and flat memory model and DOS used 16-bit code and segmented memory.  Insns using a 32-bit register would be one byte bigger; however, near call instructions would be 2 bytes smaller!  =)<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Thu Jun 29, 2006 10:05 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2006-06-29T17:17:26-07:00</updated>
<published>2006-06-29T17:17:26-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14819#p14819</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14819#p14819"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14819#p14819"><![CDATA[
Under Windows, the .com suffix is also useful for fooling n00bs into executing your rootkit, as they think it's a shortcut to some web site.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Thu Jun 29, 2006 5:17 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[byuu]]></name></author>
<updated>2006-06-29T14:51:50-07:00</updated>
<published>2006-06-29T14:51:50-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14805#p14805</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14805#p14805"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14805#p14805"><![CDATA[
Bah, pack that baby down to 256-bytes and release it as a demoscene .com app :P<br /><br />Or more realistically, it'd be kind of cool to try and design the smallest possible NES emulator in pure assembly as a .com DOS file.<br /><br />For those who use Macs, a .com file is basically an executable with no header. You can't have one bigger than 64k, and it runs in 16-bit mode but you can use 32-bit registers in it.<br /><br />TNES had one that was ~30kb, but it went up in size and eventually became a .exe file anyway.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=375">byuu</a> — Thu Jun 29, 2006 2:51 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[blargg]]></name></author>
<updated>2006-06-29T04:14:44-07:00</updated>
<published>2006-06-29T04:14:44-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14778#p14778</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14778#p14778"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14778#p14778"><![CDATA[
My 6502 emulator doesn't use any assembly, but it also doesn't emulate any unofficial instructions nor some of the more subtle aspects of read-modify-write instructions yet (dummy reads). So mozz's likely 2-3K core with unofficial instruction support will be quite an achievement.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=17">blargg</a> — Thu Jun 29, 2006 4:14 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mattmatteh]]></name></author>
<updated>2006-06-28T16:39:43-07:00</updated>
<published>2006-06-28T16:39:43-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14748#p14748</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14748#p14748"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14748#p14748"><![CDATA[
i dont think blargg uses any asm.   mine doesnt as its portable.  i will have some asm but with c code as option.  using all asm limits portability.<br /><br />matt<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=170">mattmatteh</a> — Wed Jun 28, 2006 4:39 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-06-28T15:44:27-07:00</updated>
<published>2006-06-28T15:44:27-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14738#p14738</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14738#p14738"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=14738#p14738"><![CDATA[
<div class="quotetitle">blargg wrote:</div><div class="quotecontent"><br /><div class="quotetitle">mozz wrote:</div><div class="quotecontent">'m kind of more interested in how much I can optimize code size anyways...<br /></div><br /><br />If you can get under around 4K of machine code + 1K for the jump table, you have my C++-based core beat. <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /></div><br /><br />For interest's sake:  Last weekend, I wrote by hand about 90-95% of a 6502 core (in x86 assembly code) which uses two handlers to implement each instruction.  The dispatch table will be 1K (two 16-bit fields in each entry) and so far the code size is about 750 bytes, however I am missing some code:<br />  - need more dispatch code, probably about 50 bytes worth<br />  - the memory read and write routines are not present.  They will probably weigh in around 200 bytes.<br />  - BRK and a few other instructions (one of the complex undocumented insns--ARR?--is not implemented yet) will probably add another 50 bytes or maybe even more..<br /><br />Anyway, its currently looking like the entire core will weigh about 2K including dispatch table.  I still haven't tried to assemble it or run it, and inevitably it has bugs in it.  I don't know how well it will perform (and frankly having a core that small is so cool that even if it turns out to be slower I will probably keep it that way!  hehe)<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Wed Jun 28, 2006 3:44 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[augnober]]></name></author>
<updated>2006-05-30T01:00:55-07:00</updated>
<published>2006-05-30T01:00:55-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13599#p13599</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13599#p13599"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13599#p13599"><![CDATA[
<div class="quotetitle">-_pentium5.1_- wrote:</div><div class="quotecontent"><br /><div class="quotetitle">augnober wrote:</div><div class="quotecontent">Thinking about it more, I think a different language could help a lot.<br /></div><br />What language in particular do you have in mind?</div><br />I'm not thinking of any particular language, rather just being kind of optimistic for the sake of not ruling it out.  I don't want to go too far off the topic of emulation, but I'll explain the sort of thing that I think could be of use since I didn't explain before and haven't seen mention of this subject before (although since I haven't seen it mentioned, I also unfortunately don't know anything about it and therefore don't feel right going on about it.. hmm..)<br /><br />If a high level language were designed to facilitate the saving and loading of execution state, then this would be abstracted across platforms (saving a developer from the impractically hacky/difficult platform-specific work).. and if they didn't go so far as to require the state to be transferable between platforms, then in theory, with a good optimizing compiler I don't see why it would necessarily be too slow.  At its simplest, a facility to keep track of pointers that will be relocated on load and to register heap which must be saved (not being thorough here) may be enough to put a language on its way toward the goal (while things such as being able to keep the stack organized are common to many compilers anyway - and just may need to be dealt with in more depth).  So to avoid giving the language too much burden/overhead in an attempt to make it automatically work in every situation, perhaps the application programmer would be expected to keep restoration in mind and act accordingly.  Code modification after saved state could cause trouble, but not so much as to disallow all changes.<br /><br />I bet some computer scientists have gotten obsessed with the idea of being able to stop and restore any execution state and have gone ahead and developed a high level language to support it across different platforms, even if only as a proof of concept (or to secure a grant, to graduate, whatever).  I'm not aware of any languages advertised as such though.  Strangely, I haven't felt any need for such a language since I'm generally satisfied with being able to save and load my own data.. but this project of byuu's is interesting :)  In a way, interpreted languages make it easy enough to restore state by nature.. so it's surely been done before even if by accident, but the question is whether or not someone's gone for restorable execution state and also good performance.<br /><br />If someone has made something like I'm describing with compilers which can generate code not much slower than the best C++ compilers, then I'd be interested in hearing about it :)  Or if someone has tried and there's a reason why performance is necessarily poor, I'd be interested in finding out why.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=278">augnober</a> — Tue May 30, 2006 1:00 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[-_pentium5.1_-]]></name></author>
<updated>2006-05-29T22:57:37-07:00</updated>
<published>2006-05-29T22:57:37-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13589#p13589</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13589#p13589"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13589#p13589"><![CDATA[
<div class="quotetitle">augnober wrote:</div><div class="quotecontent"><br />Thinking about it more, I think a different language could help a lot.<br /></div><br />What language in particular do you have in mind?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=499">-_pentium5.1_-</a> — Mon May 29, 2006 10:57 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[WedNESday]]></name></author>
<updated>2006-05-25T06:34:53-07:00</updated>
<published>2006-05-25T06:34:53-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13363#p13363</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13363#p13363"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13363#p13363"><![CDATA[
On what cycles are bit 7 of $2002 set and NMI executed? And in which order?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=191">WedNESday</a> — Thu May 25, 2006 6:34 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[augnober]]></name></author>
<updated>2006-05-24T23:56:03-07:00</updated>
<published>2006-05-24T23:56:03-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13353#p13353</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13353#p13353"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13353#p13353"><![CDATA[
<div class="quotetitle">byuu wrote:</div><div class="quotecontent"><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent">I imagine the best chance at a solution is in a different programming language which has this in mind, but then I suppose that even if such a language exists, the compilers currently available are bound to be slow.<br /></div><br /><br />That's exactly it. This could be done in c++ too, using save states. You either implement execution context in hardware, using CPU registers and the stack, and gain a huge speedup but lose the ability to save and restore the state cross-platform; or you implement the execution context in software, which becomes a state machine, where you have many small functions and hold execution states in memory variables, and lose a lot of speed. It's irrelevant what language you use. Hardware is always faster, but by it's very nature makes the states platform-dependant. Of course, it'd be more convenient to use a language that had this sort of functionality built in, but I like c++ too much to switch.</div><br />Thinking about it more, I think a different language could help a lot.  Before, I was thinking about the ability of a state to be saved on one platform and loaded on another.  For a strictly easier goal.. How about have cross-platform emulator code supporting savestates but only allowing the states to be restored on the same platform?  I think the proper language could be very helpful in abstracting what would be required while also not horribly maiming execution speed.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=278">augnober</a> — Wed May 24, 2006 11:56 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[byuu]]></name></author>
<updated>2006-05-24T16:23:43-07:00</updated>
<published>2006-05-24T16:23:43-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13339#p13339</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13339#p13339"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13339#p13339"><![CDATA[
<div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />Another way to look at it: In the quote above you seem to be implying a scenario where many cothreads need to synchronize at once (i.e. "have to" stop for each other) in a way that prevents you from getting them all to a "want to" point. But even if it was possible for that to happen for short periods of time (I'm not at all sure that it is), it doesn't happen most of the time. If it did, "catch up" implementations would be synchronizing so often that they would hardly perform better than lock-step simulation. The reason they perform better in practice is that the parallel tasks spend most of their time NOT interacting with each other, so close synchronization is not usually needed.<br /></div><br /><br />I'm really truly very much against the idea of playing to chance, hoping that the one rare instance where things get stuck in "have to" syncs repeatedly never occurs. In other words, if it isn't guaranteed to work, then to me it's junk.<br />I also need to do this for the PPU, and I <em>won't</em> be breaking it apart into a dot renderer. So it will have to run an entire scanline to be in a "want to" point to pause at.<br />However, if it's the only way to get savestates, perhaps I'll consider it :/<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=375">byuu</a> — Wed May 24, 2006 4:23 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[mozz]]></name></author>
<updated>2006-05-24T11:55:21-07:00</updated>
<published>2006-05-24T11:55:21-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13318#p13318</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13318#p13318"/>
<title type="html"><![CDATA[cycle for cycle stuff]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=547&amp;p=13318#p13318"><![CDATA[
<div class="quotetitle">byuu wrote:</div><div class="quotecontent"><br />Again, this becomes increasingly difficult as the number of threads increases. Let's say I need CPU, APU, PPU, DSP, and SA-1. Now if any of those five components are communicating with each other, I won't be able to take a snapshot because the waitforevent delay inside one of those will force that thread to be stuck in the middle of a function. It's a good kludge that'd probably work for CPU&lt;&gt;APU synchronization, though.<br /></div><br />I don't think this would be a problem in practice.  Consider the CPU cothread.  Once per emulated instruction (in the dispatch code), it will be at a "safe point" to save.  So as long as it isn't blocked waiting for something else to complete, you only have to advance it a relatively short amount of simulated time in order to get to a "safe point" to save.<br /><br />In other words, you might context switch away from the CPU cothread for two reasons: either because you <strong>want to</strong> (which will always be at a "safe point", e.g. at the beginning of dispatching an instruction), or because you <strong>have to</strong> (because you need to interact with a different cothread and need it to "catch up" to you before you can complete your operation, e.g. a read from a APU-&gt;CPU communication port).  In the case of "want to" points, you might want to switch to a different cothread to handle a timer interrupt, or to make sure other tasks aren't delayed for too much wall-clock time (i.e. must simulate APU often enough to keep sound buffer full of samples) or because you want to take a savestate.<br /><br />In order to arrange a save, you would just make all tasks stop at a "want to" point as soon as they can.  If one or more of them stopped at a "have to" point instead, you'd continue emulating normally, i.e. do whatever "catch up" was necessary to unblock it, until it reached a "want to" point.  Remember, "want to" points occur pretty frequently--every simulated instruction, for example--so you're not likely to "have to" suspend more than once to get to one.<br /><br />Another way to look at it:  In the quote above you seem to be implying a scenario where many cothreads need to synchronize at once (i.e. "have to" stop for each other) in a way that prevents you from getting them all to a "want to" point.  But even if it was possible for that to happen for short periods of time (I'm not at all sure that it is), it doesn't happen most of the time.  If it did, "catch up" implementations would be synchronizing so often that they would hardly perform better than lock-step simulation.  The reason they perform better in practice is that the parallel tasks spend most of their time NOT interacting with each other, so close synchronization is not usually needed.<br /><br />I'm just speculating about all of this.  At one time I was trying to come up with a formalized timing model that gave precise definitions for all of this stuff.  But I got busy doing other things.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=330">mozz</a> — Wed May 24, 2006 11:55 am</p><hr />
]]></content>
</entry>
</feed>