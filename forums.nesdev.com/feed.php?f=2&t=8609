<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-gb">
<link rel="self" type="application/atom+xml" href="http://forums.nesdev.com/feed.php?f=2&amp;t=8609" />

<title>nesdev.com</title>
<subtitle>NES Development and Strangulation Records message boards</subtitle>
<link href="http://forums.nesdev.com/index.php" />
<updated>2012-05-05T18:20:09-07:00</updated>

<author><name><![CDATA[nesdev.com]]></name></author>
<id>http://forums.nesdev.com/feed.php?f=2&amp;t=8609</id>
<entry>
<author><name><![CDATA[furrykef]]></name></author>
<updated>2012-03-02T23:21:23-07:00</updated>
<published>2012-03-02T23:21:23-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=90841#p90841</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=90841#p90841"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=90841#p90841"><![CDATA[
By an amusing coincidence, I'd done exactly this last December. <img src="http://forums.nesdev.com/images/smilies/icon_smile.gif" alt=":)" title="Smile" /> I'd never seen a Huffman tree in ASM form before, so I was quite baffled at first until I realized a table indexing into itself must be a tree, and then it all fell into place.<br /><br /><a href="http://code.google.com/p/lltvg/source/browse/#hg%2Fbtoads-script" class="postlink">This</a> repository contains the Python file I wrote to extract the script as well as batch files that supply the offsets for the US and Japanese versions of the ROM.<br /><br /><div class="quotetitle">koitsu wrote:</div><div class="quotecontent"><br />Here's an alternate theory, which I think is much more likely: did this game come out in Japan? If so, that would probably explain their choice of Huffman, which compresses Japanese amazingly well<br /></div><br />Japanese text has much less a need to be compressed in the first place than English text, because, assuming one byte per kana, it's much more efficient in the first place. I think maybe the uncompressed Japanese script is in the neighborhood of the size of the compressed English script. (I'm too lazy to check, though.) I also didn't notice anything particularly interesting about the compression ratio of the Japanese text compared to the English text; in fact, I'm fairly sure the compression ratio was higher for English.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5225">furrykef</a> — Fri Mar 02, 2012 11:21 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[rainwarrior]]></name></author>
<updated>2012-02-13T12:24:00-07:00</updated>
<published>2012-02-13T12:24:00-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89916#p89916</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89916#p89916"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89916#p89916"><![CDATA[
Yeah, I had a few ideas about how to adapt it, but I figured someone must have worked out a decent method for it already. Thanks for finding that.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5165">rainwarrior</a> — Mon Feb 13, 2012 12:24 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tokumaru]]></name></author>
<updated>2012-02-13T08:52:07-07:00</updated>
<published>2012-02-13T08:52:07-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89907#p89907</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89907#p89907"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89907#p89907"><![CDATA[
Here's the DTE variant I was talking about&#058; <a href="http://en.wikibooks.org/wiki/Data_Compression/Dictionary_compression#SCZ_byte_pair_encoding" class="postlink">http://en.wikibooks.org/wiki/Data_Compression/Dictionary_compression#SCZ_byte_pair_encoding</a><br /><br />Apparently it takes a rarely used byte and uses it as an escape code, which is used to indicate single bytes. If the most rarely used bytes are all preceded by the escape code, their codes become available for representing the most common pairs. What happens is that the least common bytes are expanded to 2 bytes, but the most common pairs are compressed to 1 byte. Also, as pairs are encoded, more characters might not appear by themselves anymore, also freeing their codes for representing compressed pairs. <br /><br />That's what I got so far, but I'm sure there's more to it.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=95">tokumaru</a> — Mon Feb 13, 2012 8:52 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tokumaru]]></name></author>
<updated>2012-02-13T04:55:04-07:00</updated>
<published>2012-02-13T04:55:04-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89903#p89903</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89903#p89903"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89903#p89903"><![CDATA[
<div class="quotetitle">rainwarrior wrote:</div><div class="quotecontent"><br />What does internal fragmentation have to do with it?<br /></div><br />I think internal fragmentation means the same as free symbols/codes in this case. Recently I read about a DTE variation that doesn't require any free codes, but I didn't really get how it works yet.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=95">tokumaru</a> — Mon Feb 13, 2012 4:55 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[rainwarrior]]></name></author>
<updated>2012-02-12T23:54:03-07:00</updated>
<published>2012-02-12T23:54:03-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89890#p89890</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89890#p89890"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89890#p89890"><![CDATA[
I said "general purpose". I'm not trying to compress anything, I'm just wondering what kind of data (if any) this algorithm can't apply to. If your data doesn't have unused symbols, is there a viable variant of the algorithm? (Or would it become complex enough that there are better compression methods for the same level of complexity?)<br /><br />I can see how it can work nicely for text. A common word would eventually be compressed down to a single character, each pass of the algorithm packing in another letter, but also other words with shared substrings would get to reuse some of the same symbols. Pretty nifty. Hmm, this seems a lot like LZ78, actually.<br /><br />What does internal fragmentation have to do with it? I don't follow why you mentioned it. Free symbols seem to be the primary requirement (for a simple implementation, at least). A lot of data has repeated multi-byte strings in it, though, which is why I'm wondering if the free symbol requirement can be relaxed.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5165">rainwarrior</a> — Sun Feb 12, 2012 11:54 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2012-02-13T09:23:07-07:00</updated>
<published>2012-02-12T22:17:16-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89886#p89886</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89886#p89886"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89886#p89886"><![CDATA[
<div class="quotetitle">rainwarrior wrote:</div><div class="quotecontent"><br />Looking at that [section about canonical Huffman codes in the Huffword] article, I guess this case it could be gotten down to 22 bytes (44 4-bit bitcode length values)<br /></div><br />Actually it's one byte for each bit length, not for each distinct symbol. For example, if codes are up to 13 bits long as in the Battletoads tree, the description would be 13 bytes, followed by the 43 or so bytes for the actual values sorted by increasing bit length (i.e. decreasing frequency).<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />and I'm not sure this wouldn't add another 62 to the decompressor.<br /></div><br />Which means the only way for me to settle it would be to write a demo of CH decompression.<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />If you had lots of tables though it could be worthwhile.<br /></div><br />Or if you had a huge table, like the table used for Huffword.<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />Another thing I'm wondering about byte-pair encoding is that you need extra symbols for your substitutions. For text stored as bytes it's probably great, since you've got tons of unused symbols at the ready, but for general purpose...<br /></div><br />What are you trying to compress that can be modeled by byte pairs but doesn't have any built-in <a href="http://en.wikipedia.org/wiki/Fragmentation_%28computing%29#Internal_fragmentation" class="postlink">internal fragmentation</a> for digram coding to exploit? CHR data?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sun Feb 12, 2012 10:17 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[rainwarrior]]></name></author>
<updated>2012-02-12T20:40:41-07:00</updated>
<published>2012-02-12T20:18:23-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89882#p89882</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89882#p89882"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89882#p89882"><![CDATA[
Well, 1994 is the earliest cited example; why would I assume there's something earlier unless someone tells me there is?<br /><br />I tried a quick search of Romhacking.NET but all I'm finding is that people are commonly hacking an implementation of DTE into old ROMs to make themselves more room to translate into English, which is a pretty cool application of it. I'd love to know if/when it first appeared in an original game though.<br /><br />I was wondering if decompression was slow, not the compression part, but I hadn't realized it could decompress as a tree; I was thinking it would scan the string and rebuild it with each substitution one at a time, but realizing you could apply them recursively, I guess the decompression time wouldn't be that bad at all. (This is a pretty neat method. Thanks for mentioning it!)<br /><br />Also, the size of the huffman table isn't necessarily an issue; I was just mentioning it because it is there. For text of any size worth compressing, it's probably negligible. In this case it was 84 bytes, not a big deal. Looking at that article, I guess this case it could be gotten down to 22 bytes (44 4-bit bitcode length values), and I'm not sure this wouldn't add another 62 to the decompressor. If you had lots of tables though it could be worthwhile.<br /><br />Another thing I'm wondering about byte-pair encoding is that you need extra symbols for your substitutions. For text stored as bytes it's probably great, since you've got tons of unused symbols at the ready, but for general purpose... the algorithm can probably be adapted to get around this problem, but it might get a bit more complicated?<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5165">rainwarrior</a> — Sun Feb 12, 2012 8:18 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2012-02-12T19:54:27-07:00</updated>
<published>2012-02-12T19:54:27-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89880#p89880</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89880#p89880"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89880#p89880"><![CDATA[
<div class="quotetitle">rainwarrior wrote:</div><div class="quotecontent"><br />though storing the tree itself will put you over by the size of the tree<br /></div><br />And even that can be minimized. Instead of storing each element of the tree, store only the number of symbols with each bit length. Such a "canonical Huffman" code has a very compact representation, as I described in <a href="http://pineight.com/mw/?title=Huffword" class="postlink">my article about Huffword</a>.<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />Digram coding [...] could be very slow, since it's liable to have many passes<br /></div><br />Which is probably tolerable for three reasons: <ul><li>PCs are real fast nowadays, and they can afford to make numerous passes over a text. </li><li>If you're doing the compression on a PC, you can build the digram tree on one core and compile the rest of the program on another core. </li><li>The statistics for an entire corpus aren't likely to change much over the course of one day. You could rebuild the digram tree only once a day and then just reuse the same tree, even if it has become slightly suboptimal, when reencoding your corpus. </li></ul><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />What Super NES RPGs used it?<br /></div><br />Romhacking.net would be able to answer that one best. (They know it by the name DTE rather than the academic name "digram coding".)<br /><br /><div class="quotetitle"><b>Quote:</b></div><div class="quotecontent"><br />(I guess being invented in 1994 it would have been limited to later ones...)<br /></div><br />The 1994 date has to be taken in the context of <a href="http://en.wikipedia.org/wiki/Wikipedia:Verifiability" class="postlink">Wikipedia's verifiability policy</a>. Wikipedia considers only <a href="http://en.wikipedia.org/wiki/Wikipedia:Identifying_reliable_sources" class="postlink">"reliable" sources</a> available to the public (whether free or paid). So even if games used it before then, unless it was explained in a published article, it doesn't count.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sun Feb 12, 2012 7:54 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[rainwarrior]]></name></author>
<updated>2012-02-12T19:43:40-07:00</updated>
<published>2012-02-12T19:43:40-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89879#p89879</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89879#p89879"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89879#p89879"><![CDATA[
byuu, if all of your symbols had equal probability (worst case for huffman) the resulting huffman tree would be the same as fixed-bit-length (though storing the tree itself will put you over by the size of the tree). Best case for huffman I guess would be all the same symbol, which could be represented by a single bit, giving you 8:1 compression. Obviously you won't get near that, in generall, but it's a lower bound on the possible compressed size. For Battletoads it works out to maybe 4.7 bits per byte (you'd need 6 for a fixed-bit encoding, or about 5.5 if you built a tree that matches the number of symbols, but at that point you should just go with huffman).<br /><br />tepples mentioned its primary weakness; it starts with the premise of only looking at individual bytes and trying to compress them. You can try to do better with longer strings, words, or other things that seem appropriate to your data; the spaces after a newline in Battletoads are RLEd as a minor adaptation (it's not entirely successful; the tree produced a bitcode for \n+2 that is longer than \n with 2 individual spaces, for instance).<br /><br />Digram coding sounds interesting; very elegant! I'd never heard of it. Though I suspect it could be very slow, since it's liable to have many passes (even worse if you need to do it in place). Might be acceptable for shorter texts. What Super NES RPGs used it? (I guess being invented in 1994 it would have been limited to later ones...)<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5165">rainwarrior</a> — Sun Feb 12, 2012 7:43 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[tepples]]></name></author>
<updated>2012-02-12T18:20:26-07:00</updated>
<published>2012-02-12T18:20:26-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89875#p89875</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89875#p89875"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89875#p89875"><![CDATA[
Huffman coding is optimal where the probability of a symbol doesn't depend on the symbols surrounding it. English, on the other hand, is very context-sensitive. Once I considered Huffman with the optimization of finding the most common character following each given character and then swapping the code for that character with the code for a space. It saved a little but not very much.<br /><br /><a href="http://en.wikipedia.org/wiki/Byte_pair_encoding" class="postlink">Digram coding</a> (aka BPE or DTE) is a context-sensitive technique used in many Super NES RPGs. <a href="http://pineight.com/mw/?title=Huffword" class="postlink">Huffword</a> is another context-sensitive technique that works well on really long texts, reducing a novel by 60% or more. But the amount of text in an NES game's cut scenes might not be enough to take full advantage of this context; Huffword found too many <a href="http://en.wikipedia.org/wiki/Hapax_legomenon" class="postlink">hapax legomena</a> (words occurring once that would need to be encoded with character-based Huffman coding) when I ran it on the script of Thwaite.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=9">tepples</a> — Sun Feb 12, 2012 6:20 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[rainwarrior]]></name></author>
<updated>2012-05-05T18:02:03-07:00</updated>
<published>2012-02-12T14:06:55-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89868#p89868</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89868#p89868"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89868#p89868"><![CDATA[
So I got bored and made a graph of the Huffman tree:<br /><a href="http://rainwarrior.ca/projects/nes/battletoads_huffman.png" class="postlink">http://rainwarrior.ca/projects/nes/battletoads_huffman.png</a><p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5165">rainwarrior</a> — Sun Feb 12, 2012 2:06 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Bregalad]]></name></author>
<updated>2012-02-12T06:57:08-07:00</updated>
<published>2012-02-12T06:57:08-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89864#p89864</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89864#p89864"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89864#p89864"><![CDATA[
I think huffman works well on any text data, no matter the language (as long as the tree is adapted to the language of course), as in all languages some letters (or symbols, as not all languages uses letters) comes more frequently than others.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=38">Bregalad</a> — Sun Feb 12, 2012 6:57 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[byuu]]></name></author>
<updated>2012-02-12T02:51:01-07:00</updated>
<published>2012-02-12T02:51:01-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89863#p89863</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89863#p89863"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89863#p89863"><![CDATA[
<div class="quotetitle">koitsu wrote:</div><div class="quotecontent"><br />I'm surprised they used <a href="http://en.wikipedia.org/wiki/Huffman_coding" class="postlink">Huffman</a>.  Huffman really doesn't provide very many benefits for English (ASCII) character sets.<br /></div><br /><br />Pretty much the main reason to use it is because you can start decompressing right in the middle of a block of text. You try that with LZ and you'll need lots of RAM to hold your window, and more time to process all of the text up to that point.<br /><br />Would be interesting to compare it to a 6-bit (upper+lower) or 5-bit (upper only) bit-pack, see how much space they actually saved. Rough guess from past experiences, I'd say 10-20% more.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=375">byuu</a> — Sun Feb 12, 2012 2:51 am</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[rainwarrior]]></name></author>
<updated>2012-05-05T18:20:09-07:00</updated>
<published>2012-02-11T22:15:08-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89860#p89860</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89860#p89860"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89860#p89860"><![CDATA[
Yes, there was a Japanese version, but it was developed in Britain. I doubt the decision to use huffman had anything to do with it being theoretically good for Japanese text. They had one 32k bank dedicated to cutscenes, and they managed to squeeze an extra 4k out of it, so... why not? There's very little fill space left over in this page of the ROM. Possibly they wrote so much random variant text to fill up the space!<br /><br />The ROM filename is specified in the python file. ("Battletoads (U).nes") If you're trying it out and you don't seem to have the right ROM you could just e-mail me I guess. I don't really care if it's not robust across different ROM versions, it's a one-use program anyway. I could just send you <a href="http://rainwarrior.ca/projects/nes/Battletoads%20%28U%29%20script.txt" class="postlink">the output</a> even. I posted it because it's interesting how it works; and it could trivially be adapted for the other ROM versions.<br /><br />The specfic huffman table was obviously generated from the set of text they had. I believe the symbol table is stored in order of frequency, and it looks like:<br />space, E, T, O, A, S, R, N, H, '\n', I, U, D, L, Y, G, '!', ''', C, M, B, ',', W, P, F, '\n', end, K, '-', '.', V, '\n' + 2 spaces, '\n' + 1, '\n' + 3, '\n' + 5, '\n' + 4, '\n' + 6, '\n' + 7, '?', Z, Q, J, X, '\n' + 8, '?' (don't ask me why there's two)<br /><br />I haven't bothered to actually reconstruct the decoding tree, but you can do it if you're interested.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=5165">rainwarrior</a> — Sat Feb 11, 2012 10:15 pm</p><hr />
]]></content>
</entry>
<entry>
<author><name><![CDATA[Dwedit]]></name></author>
<updated>2012-02-11T21:56:56-07:00</updated>
<published>2012-02-11T21:56:56-07:00</published>
<id>http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89859#p89859</id>
<link href="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89859#p89859"/>
<title type="html"><![CDATA[Battletoads text decompression (huffman)]]></title>

<content type="html" xml:base="http://forums.nesdev.com/viewtopic.php?t=8609&amp;p=89859#p89859"><![CDATA[
Japanese Battletoads used Hiragana mixed with English for all names and other proper nouns.  It's really weird.  Normally you'd expect Katakana instead.<p>Statistics: Posted by <a href="http://forums.nesdev.com/memberlist.php?mode=viewprofile&amp;u=53">Dwedit</a> — Sat Feb 11, 2012 9:56 pm</p><hr />
]]></content>
</entry>
</feed>